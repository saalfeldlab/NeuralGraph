# Signal N11_1 Experiment Series - Noise Robustness in Chaotic RNN

## Summary

Testing GNN's ability to learn chaotic RNN dynamics with varying noise levels during training.

**Data Generation**: PDE_N11 simulator ([notebooks/rnn_models.ipynb](../../src/NeuralGraph/notebooks/rnn_models.ipynb))
**Model**: Signal_Propagation GNN
**Trainer**: graph_trainer.py (data_train_signal)

---

## Experiment Table

| Config         | Dataset        | noise_level | RÂ² @ convergence | Runtime | Notes        |
|:---------------|:---------------|:-----------:|:----------------:|:-------:|:-------------|
| signal_N11_1_1 | signal_N11_1   | 0.0         | [Pending]        | -       | Baseline     |
| signal_N11_1_2 | signal_N11_1   | 0.0         | [Pending]        | -       | Repeat       |
| signal_N11_1_3 | signal_N11_1   | 0.0         | [Pending]        | -       | Repeat       |
| signal_N11_1_4 | signal_N11_1_4 | 0.5         | [Pending]        | -       | Medium noise |
| signal_N11_1_5 | signal_N11_1_5 | 1.0         | [Pending]        | -       | High noise   |
| signal_N11_1_6 | signal_N11_1_6 | 2.0         | [Pending]        | -       | High noise   |
| signal_N11_1_7 | signal_N11_1_7 | 5.0         | [Pending]        | -       | Very high    |

---

## Configuration

### RNN Dynamics (PDE_N11)
```python
du/dt = -c*u + g * W * tanh(u)

# Parameters
n_neurons: 100
n_neuron_types: 1
delta_t: 0.1
connectivity_type: 'chaotic'
g: 7.0  # Gain (chaotic regime)
c: 1.0  # Decay constant
```

### GNN Model
```python
signal_model_name: 'PDE_N11'
prediction: 'first_derivative'
hidden_dim: 64
n_layers: 3
embedding_dim: 2
```

### Training
```python
n_epochs: 10
n_runs: 2
batch_size: 8
data_augmentation_loop: 50

learning_rate_W_start: 1.0E-3
learning_rate_start: 5.0E-4
learning_rate_embedding_start: 5.0E-3

coeff_W_L1: 1.0E-5
init_training_single_type: True
```

---

## Key Questions

- [ ] How does noise affect learning quality?
- [ ] Optimal noise level for robustness vs accuracy?
- [ ] Does model trained on noisy data generalize better?
- [ ] Compare convergence speed across noise levels

---

## Notes

- **init_training_single_type: True**: All neurons initialized as same type
- **Pure chaotic dynamics**: No external input
- **Noise range**: 0.0 (clean) to 5.0 (very noisy)
