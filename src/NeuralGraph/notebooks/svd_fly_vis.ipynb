{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24850553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.jit\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.neighbors\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import polars as pl\n",
    "import scipy.stats\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f2f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sim_dir = \"/groups/saalfeld/home/allierc/Py/NeuralGraph/graphs_data/fly/fly_N9_54_1\"\n",
    "# use local copy - faster\n",
    "sim_dir = \"/mnt/localdata/fly_N9_54_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b44fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load(f\"{sim_dir}/x_list_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befbbf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, num_cells, _ = x.shape\n",
    "print(x.shape, x.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf57435",
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_types = x[0, :, 6].astype(np.int32)\n",
    "\n",
    "neuron_type_name = [\n",
    "    \"Am\",\n",
    "    \"C2\",\n",
    "    \"C3\",\n",
    "    \"CT1(Lo1)\",\n",
    "    \"CT1(M10)\",\n",
    "    \"L1\",\n",
    "    \"L2\",\n",
    "    \"L3\",\n",
    "    \"L4\",\n",
    "    \"L5\",\n",
    "    \"Lawf1\",\n",
    "    \"Lawf2\",\n",
    "    \"Mi1\",\n",
    "    \"Mi10\",\n",
    "    \"Mi11\",\n",
    "    \"Mi12\",\n",
    "    \"Mi13\",\n",
    "    \"Mi14\",\n",
    "    \"Mi15\",\n",
    "    \"Mi2\",\n",
    "    \"Mi3\",\n",
    "    \"Mi4\",\n",
    "    \"Mi9\",\n",
    "    \"R1\",\n",
    "    \"R2\",\n",
    "    \"R3\",\n",
    "    \"R4\",\n",
    "    \"R5\",\n",
    "    \"R6\",\n",
    "    \"R7\",\n",
    "    \"R8\",\n",
    "    \"T1\",\n",
    "    \"T2\",\n",
    "    \"T2a\",\n",
    "    \"T3\",\n",
    "    \"T4a\",\n",
    "    \"T4b\",\n",
    "    \"T4c\",\n",
    "    \"T4d\",\n",
    "    \"T5a\",\n",
    "    \"T5b\",\n",
    "    \"T5c\",\n",
    "    \"T5d\",\n",
    "    \"Tm1\",\n",
    "    \"Tm16\",\n",
    "    \"Tm2\",\n",
    "    \"Tm20\",\n",
    "    \"Tm28\",\n",
    "    \"Tm3\",\n",
    "    \"Tm30\",\n",
    "    \"Tm4\",\n",
    "    \"Tm5Y\",\n",
    "    \"Tm5a\",\n",
    "    \"Tm5b\",\n",
    "    \"Tm5c\",\n",
    "    \"Tm9\",\n",
    "    \"TmY10\",\n",
    "    \"TmY13\",\n",
    "    \"TmY14\",\n",
    "    \"TmY15\",\n",
    "    \"TmY18\",\n",
    "    \"TmY3\",\n",
    "    \"TmY4\",\n",
    "    \"TmY5a\",\n",
    "    \"TmY9\",\n",
    "]\n",
    "neuron_type_index = {t: i for i, t in enumerate(neuron_type_name)}\n",
    "\n",
    "\n",
    "def compute_ixs_per_type(neuron_types):\n",
    "    \"\"\"Compute indices corresponding to each neuron type.\"\"\"\n",
    "    order = np.argsort(neuron_types)\n",
    "    uniq_types, start_index = np.unique(neuron_types[order], return_index=True)\n",
    "    num_neuron_types = len(uniq_types)\n",
    "    assert (uniq_types == np.arange(num_neuron_types)).all(), \"breaks assumptions\"\n",
    "    breaks = np.zeros(len(uniq_types) + 1, dtype=np.int64)\n",
    "    breaks[:-1] = start_index\n",
    "    breaks[-1] = len(neuron_types)\n",
    "    return [order[breaks[i] : breaks[i + 1]] for i in range(num_neuron_types)]\n",
    "\n",
    "\n",
    "neuron_ixs_by_type = compute_ixs_per_type(neuron_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee79330",
   "metadata": {},
   "outputs": [],
   "source": [
    "BURNIN_OFFSET = 100\n",
    "OBS_TIME_STEPS = 20\n",
    "\n",
    "obs_ca = x[BURNIN_OFFSET::OBS_TIME_STEPS, :, 7].copy()\n",
    "train_start = 0\n",
    "validation_start = 3000\n",
    "test_start = 3500\n",
    "\n",
    "train_mat = obs_ca[train_start:validation_start]\n",
    "val_mat = obs_ca[validation_start:test_start]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6594d33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stimulus = gaussian_filter1d(x[BURNIN_OFFSET:, :, 4], sigma=OBS_TIME_STEPS / 2)[\n",
    "    ::OBS_TIME_STEPS\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147ac27",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_stimulus = stimulus[train_start:validation_start]\n",
    "val_stimulus = stimulus[validation_start:test_start]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823ad64e",
   "metadata": {},
   "source": [
    "## aside: spectral embedding of graph - see hexagonal structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd6c023",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load some simulation network params\n",
    "\n",
    "wt = torch.load(f\"{sim_dir}/weights.pt\")\n",
    "edge_index = torch.load(f\"{sim_dir}/edge_index.pt\")\n",
    "voltage_rest = torch.load(f\"{sim_dir}/V_i_rest.pt\")\n",
    "taus = torch.load(f\"{sim_dir}/taus.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4fa4ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "def spectral_embed(E, N, edim):\n",
    "    \"\"\"\n",
    "    Perform a 2D spectral embedding of a directed graph.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    E : np.ndarray\n",
    "        2×M array of edges, where E[0, i] is the source and E[1, i] is the target.\n",
    "        Nodes are labeled 0,…,N-1.\n",
    "    N : int\n",
    "        Total number of nodes.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords : np.ndarray of shape (N, 2)\n",
    "        The 2D spectral embedding coordinates for each node (rows correspond to nodes).\n",
    "    \"\"\"\n",
    "    # --- 1. Build sparse adjacency matrix ---\n",
    "    src, dst = E\n",
    "    data = np.ones(len(src), dtype=float)\n",
    "    A = sparse.coo_matrix((data, (src, dst)), shape=(N, N))\n",
    "\n",
    "    # --- 2. Make adjacency symmetric (convert to undirected for Laplacian) ---\n",
    "    A = ((A + A.T) > 0).astype(float)\n",
    "\n",
    "    # --- 3. Compute normalized Laplacian L = I - D^{-1/2} A D^{-1/2} ---\n",
    "    deg = np.array(A.sum(axis=1)).flatten()\n",
    "    D_inv_sqrt = sparse.diags(1.0 / np.sqrt(np.maximum(deg, 1e-12)))\n",
    "    L = sparse.eye(N) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "    # --- 4. Compute 2nd and 3rd smallest eigenvectors (skip trivial one) ---\n",
    "    vals, vecs = eigsh(L, k=edim + 1, which=\"SM\")\n",
    "    coords = vecs[:, 1 : edim + 1]\n",
    "\n",
    "    return coords\n",
    "\n",
    "\n",
    "def spectral_embed_2d_weighted(E, W, N):\n",
    "    \"\"\"\n",
    "    Spectral embedding of a possibly signed, weighted directed graph.\n",
    "    Converts to an undirected signed graph for embedding.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    E : np.ndarray, shape (2, M)\n",
    "        Edge endpoints (source, target).\n",
    "    W : np.ndarray, shape (M,)\n",
    "        Edge weights (can be positive or negative).\n",
    "    N : int\n",
    "        Number of nodes (0..N-1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    coords : np.ndarray, shape (N, 2)\n",
    "        2D spectral embedding coordinates for each node.\n",
    "    \"\"\"\n",
    "    src, dst = E\n",
    "\n",
    "    # --- 1. Build sparse weighted adjacency matrix ---\n",
    "    A = sparse.coo_matrix((W, (src, dst)), shape=(N, N))\n",
    "    # Symmetrize (take average to preserve sign symmetry)\n",
    "    A = 0.5 * (A + A.T)\n",
    "\n",
    "    # --- 2. Degree matrix (based on absolute weights to stay PSD) ---\n",
    "    deg = np.array(np.abs(A).sum(axis=1)).flatten()\n",
    "    D_inv_sqrt = sparse.diags(1.0 / np.sqrt(np.maximum(deg, 1e-12)))\n",
    "\n",
    "    # --- 3. Normalized signed Laplacian ---\n",
    "    L = sparse.eye(N) - D_inv_sqrt @ A @ D_inv_sqrt\n",
    "\n",
    "    # --- 4. Compute smallest nontrivial eigenvectors ---\n",
    "    vals, vecs = eigsh(L, k=3, which=\"SM\")\n",
    "    coords = vecs[:, 1:3]  # skip trivial eigenvector\n",
    "\n",
    "    return coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e1e30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eembed = spectral_embed(edge_index.cpu().numpy(), voltage_rest.shape[0], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1da53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(eembed[:, 0], eembed[:, 1], alpha=0.1, marker=\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a9ac78",
   "metadata": {},
   "source": [
    "## Find the optimal SVD dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8039759",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndims = np.array([8, 16, 32, 64, 128])\n",
    "\n",
    "recon_train = np.zeros((len(ndims), train_mat.shape[0], train_mat.shape[1]))\n",
    "recon_val = np.zeros((len(ndims), val_mat.shape[0], val_mat.shape[1]))\n",
    "\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=ndims.max(), random_state=321)\n",
    "proj = svd.fit_transform(train_mat)\n",
    "proj_val = svd.transform(val_mat)\n",
    "for i, n in enumerate(ndims):\n",
    "    recon_train[i, :, :] = np.matmul(proj[:, :n], svd.components_[:n, :])\n",
    "    recon_val[i, :, :] = np.matmul(proj_val[:, :n], svd.components_[:n, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c54d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_train = recon_train - train_mat[np.newaxis, :, :]\n",
    "delta_val = recon_val - val_mat[np.newaxis, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5eca758",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute variance along the time dimension\n",
    "# We are most interested in learning about the dynamics per neuron\n",
    "# So we focus on this dimension rather than along neuron space\n",
    "\n",
    "var_train = np.var(train_mat, axis=0)\n",
    "var_train_unexpl = np.var(delta_train, axis=1)\n",
    "r2_train = 1 - var_train_unexpl / var_train\n",
    "var_val = np.var(val_mat, axis=0)\n",
    "var_val_unexpl = np.var(delta_val, axis=1)\n",
    "r2_val = 1 - var_val_unexpl / var_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d0a855",
   "metadata": {},
   "outputs": [],
   "source": [
    "den, edges = np.histogram(var_train, bins=15)\n",
    "for i, n in enumerate(ndims):\n",
    "    num, _ = np.histogram(\n",
    "        var_train, bins=edges, weights=(r2_train[i] < 0).astype(np.float32)\n",
    "    )\n",
    "    plt.plot(edges[1:], num / den, label=f\"L={n}\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Fraction R2 < 0\")\n",
    "plt.xlabel(\"Variance of neuron time trace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27377f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "den, edges = np.histogram(var_train, bins=15)\n",
    "for i, n in enumerate(ndims):\n",
    "    num, _ = np.histogram(var_train, bins=edges, weights=r2_train[i])\n",
    "    plt.plot(edges[1:], num / den, label=f\"L={n}\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Mean R2\")\n",
    "plt.xlabel(\"Variance of neuron time trace\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f33f6e",
   "metadata": {},
   "source": [
    "## Fix latent dimension=256 and proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c9a5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 256\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=L)\n",
    "svd.fit(train_mat)\n",
    "\n",
    "# import scipy.sparse.linalg\n",
    "# U, S, VT = scipy.sparse.linalg.svds(train_mat, k=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a410a6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = svd.transform(val_mat)\n",
    "recon = np.dot(proj, svd.components_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdfaa22",
   "metadata": {},
   "source": [
    "### analyze how well we can reconstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e8ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assess how good the reconstruction is across neurons (on validation data)\n",
    "\n",
    "delta = recon - val_mat\n",
    "# noise per time point in the reconstructing from the latent space\n",
    "err_t = delta.std(axis=1)\n",
    "# signal variation\n",
    "sigma_t = val_mat.std(axis=1)\n",
    "plt.scatter(sigma_t, err_t, marker=\".\", alpha=0.5)\n",
    "plt.xlabel(\"Sigma across neurons\")\n",
    "plt.ylabel(\"Reconstruction sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f980189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Errors are gaussian\n",
    "for i in np.random.randint(val_mat.shape[1], size=5):\n",
    "    s = np.std(val_mat[:, i])\n",
    "    plt.hist(delta[:, i], histtype=\"step\", label=f\"neuron {i} (sigma={s:.2f})\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0343382a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.random.randint(val_mat.shape[0], size=5):\n",
    "    s = np.std(val_mat[i])\n",
    "    plt.hist(delta[i], histtype=\"step\", label=f\"time {i} (sigma={s:.2f})\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06fb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How well do we capture the variation over time using the reconstruction\n",
    "\n",
    "# error sigma per neuron\n",
    "err_n = delta.std(axis=0)\n",
    "# signal variation\n",
    "sigma_n = train_mat.std(axis=0)\n",
    "plt.scatter(sigma_n, err_n, marker=\".\", alpha=0.2)\n",
    "plt.xlabel(\"Sigma across time\")\n",
    "plt.ylabel(\"Reconstruction sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87a7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "for ix in np.sort(np.random.randint(val_mat.shape[1], size=1)):\n",
    "    p = plt.plot(val_mat[:, ix], label=f\"Neuron {ix} original\")\n",
    "    plt.plot(\n",
    "        recon[:, ix], c=p[-1].get_color(), ls=\"\", marker=\".\", label=f\"Neuron {ix} recon\"\n",
    "    )\n",
    "plt.xlabel(\"time\")\n",
    "plt.legend(bbox_to_anchor=(1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bcd5f5f",
   "metadata": {},
   "source": [
    "## learn the latent space update (linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c9dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da9f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.compile(\n",
    "    fullgraph=True,\n",
    "    mode=\"reduce-overhead\",\n",
    "    #    mode=\"max-autotune\"\n",
    ")\n",
    "def loss_fn(evolve_mat, train_proj):\n",
    "    nmin = 1\n",
    "    nmax = 2\n",
    "    loss = torch.as_tensor(0.0, device=torch.device(\"cuda\"))\n",
    "    for i in range(nmin, nmax):\n",
    "        emat = torch.matrix_power(evolve_mat, i)\n",
    "        loss += torch.pow(\n",
    "            torch.linalg.matmul(train_proj[:-i, :], emat) - train_proj[i:], 2\n",
    "        ).mean()\n",
    "    return loss\n",
    "\n",
    "\n",
    "# matrix initialized to 1+epsilon\n",
    "init_mat = (torch.eye(L) + (torch.rand((L, L)) - 0.5) / 3.0).to(device)\n",
    "evolve_mat = torch.nn.Parameter(init_mat)\n",
    "\n",
    "train_proj = torch.tensor(svd.transform(train_mat), device=device)\n",
    "optimizer = torch.optim.Adam([evolve_mat], lr=1e-3)\n",
    "\n",
    "# train_loop(evolve_mat, train_proj, optimizer)\n",
    "loop = tqdm.trange(10_000, ncols=100)\n",
    "for t in loop:\n",
    "    loss = loss_fn(evolve_mat, train_proj)\n",
    "    if t % 10 == 0:\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c8f19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learned_mat = evolve_mat.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690d1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(learned_mat, vmax=1, vmin=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2d4cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(seed=321)\n",
    "# t0s = rng.integers(0, train_mat.shape[0]-30, size=5)\n",
    "\n",
    "T = 30\n",
    "t0 = 1000\n",
    "x0 = train_mat[t0 : t0 + 1, :]\n",
    "p0 = svd.transform(x0)\n",
    "\n",
    "results = [p0]\n",
    "for t in range(T):\n",
    "    x1 = np.matmul(results[-1], learned_mat)\n",
    "    results.append(x1)\n",
    "pred_trace = np.stack([np.matmul(r, svd.components_) for r in results], axis=0)\n",
    "act_trace = train_mat[t0 : t0 + T + 1]\n",
    "recon_each = svd.inverse_transform(svd.transform(train_mat[t0 : t0 + T + 1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4017e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neuron_types = np.sort(np.random.choice(neuron_type_name, 10))\n",
    "# ['R1', 'R7', 'C2', 'Mi11', 'Tm1', 'Tm4', 'Tm30']\n",
    "\n",
    "_, ax = plt.subplots(len(plot_neuron_types), 1, figsize=(8, 12), sharex=True)\n",
    "tvals = np.arange(t0, t0 + T + 1)\n",
    "rng = np.random.default_rng(seed=123)\n",
    "picks = [rng.choice(nixs) for nixs in neuron_ixs_by_type]\n",
    "\n",
    "for i, ptype in enumerate(plot_neuron_types):\n",
    "    nix = picks[neuron_type_index[ptype]]\n",
    "    true_trace = train_mat[t0 : t0 + T + 1, nix]\n",
    "    ax[i].plot(tvals, true_trace)\n",
    "    ax[i].set_ylim(true_trace.min() * 0.8, true_trace.max() * 1.2)\n",
    "    # time evolve\n",
    "    ax[i].plot(\n",
    "        tvals,\n",
    "        pred_trace[:, 0, nix],\n",
    "        color=p[-1].get_color(),\n",
    "        ls=\"dotted\",\n",
    "        label=\"learn linear evolver\",\n",
    "    )\n",
    "\n",
    "    # reconstruct each point using SVD\n",
    "    # ax[i].plot(tvals, recon_each[:, nix], color=p[-1].get_color(), ls=\"dashed\", marker=\".\", label=\"reconstruct each time point\")\n",
    "    ax[i].set_ylabel(ptype)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c36754",
   "metadata": {},
   "outputs": [],
   "source": [
    "nix = np.random.randint(0, train_mat.shape[1])\n",
    "print(f\"{nix=}\")\n",
    "plt.figure(figsize=(16, 6))\n",
    "\n",
    "\n",
    "# actual trace\n",
    "trace = train_mat[t0 : t0 + T + 1, nix]\n",
    "p = plt.plot(tvals, trace, label=\"actual trace\")\n",
    "\n",
    "# time evolve\n",
    "plt.plot(\n",
    "    tvals,\n",
    "    pred_trace[:, 0, nix],\n",
    "    color=p[-1].get_color(),\n",
    "    ls=\"dotted\",\n",
    "    label=\"learn linear evolver\",\n",
    ")\n",
    "\n",
    "# reconstruct each point using SVD\n",
    "plt.plot(\n",
    "    tvals,\n",
    "    recon_each[:, nix],\n",
    "    color=p[-1].get_color(),\n",
    "    ls=\"dashed\",\n",
    "    label=\"reconstruct each time point\",\n",
    ")\n",
    "\n",
    "plt.axvline(t0 + 10, color=\"k\", ls=\"dotted\")\n",
    "plt.xticks(tvals)\n",
    "\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Ca activity\")\n",
    "plt.legend()\n",
    "plt.title(f\"Neuron trace {nix=}\")\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711c1836",
   "metadata": {},
   "source": [
    "## Try a non-linear update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e16988",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b18006",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.jit.ScriptModule):\n",
    "    def __init__(self, num_latent_dims, num_hidden_units, num_hidden_layers):\n",
    "        super().__init__()\n",
    "        self.layers = torch.nn.ModuleList()\n",
    "        input_dims = num_latent_dims\n",
    "        for i in range(num_hidden_layers):\n",
    "            self.layers.append(torch.nn.Linear(input_dims, num_hidden_units))\n",
    "            self.layers.append(torch.nn.ReLU())\n",
    "            input_dims = num_hidden_units\n",
    "        self.output = torch.nn.Linear(num_hidden_units, num_latent_dims)\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def forward(self, x):\n",
    "        y = x\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            if i == 0:\n",
    "                y = layer(y)\n",
    "            else:\n",
    "                y = y + layer(y)\n",
    "        return x + self.output(y)\n",
    "\n",
    "    @torch.jit.script_method\n",
    "    def loss_fn(self, x):\n",
    "        loss = torch.as_tensor(0.0, device=torch.device(\"cuda\"))\n",
    "        start = torch.zeros_like(x, device=torch.device(\"cuda\"))\n",
    "        start[:, :] = x[:, :]\n",
    "        for i in range(1, 5):\n",
    "            end = self.forward(start)\n",
    "            loss += torch.pow(x[i:] - end[:-i], 2).mean()\n",
    "            start = end\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd71e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLP(num_latent_dims=L, num_hidden_units=8, num_hidden_layers=3).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d25bab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proj = torch.tensor(svd.transform(train_mat), device=device)\n",
    "optimizer = torch.optim.Adam(mlp.parameters(), lr=1e-3)\n",
    "\n",
    "loop = tqdm.trange(10_000, ncols=100)\n",
    "for t in loop:\n",
    "    loss = mlp.loss_fn(train_proj)\n",
    "    if t % 100 == 0:\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loop = tqdm.trange(10_000, ncols=100)\n",
    "for t in loop:\n",
    "    loss = mlp.loss_fn(train_proj)\n",
    "    if t % 100 == 0:\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720e9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.default_rng(seed=321)\n",
    "# t0s = rng.integers(0, train_mat.shape[0]-30, size=5)\n",
    "\n",
    "T = 30\n",
    "t0 = 1000\n",
    "x0 = train_mat[t0 : t0 + 1, :]\n",
    "p0 = svd.transform(x0)\n",
    "\n",
    "results = [p0]\n",
    "for t in range(T):\n",
    "    x1 = mlp(torch.tensor(results[-1], device=device))\n",
    "    results.append(x1.detach().cpu().numpy())\n",
    "pred_trace = np.stack([svd.inverse_transform(r) for r in results], axis=0)\n",
    "act_trace = train_mat[t0 : t0 + T + 1]\n",
    "recon_each = svd.inverse_transform(svd.transform(train_mat[t0 : t0 + T + 1, :]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57bd4218",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neuron_types = np.sort(np.random.choice(neuron_type_name, 8))\n",
    "# ['R1', 'R7', 'C2', 'Mi11', 'Tm1', 'Tm4', 'Tm30']\n",
    "\n",
    "_, ax = plt.subplots(len(plot_neuron_types), 1, figsize=(8, 12), sharex=True)\n",
    "tvals = np.arange(t0, t0 + T + 1)\n",
    "rng = np.random.default_rng(seed=123)\n",
    "picks = [rng.choice(nixs) for nixs in neuron_ixs_by_type]\n",
    "\n",
    "for i, ptype in enumerate(plot_neuron_types):\n",
    "    nix = picks[neuron_type_index[ptype]]\n",
    "    true_trace = train_mat[t0 : t0 + T + 1, nix]\n",
    "    ax[i].plot(tvals, true_trace)\n",
    "    ax[i].set_ylim(true_trace.min() * 0.8, true_trace.max() * 1.2)\n",
    "    # time evolve\n",
    "    ax[i].plot(\n",
    "        tvals,\n",
    "        pred_trace[:, 0, nix],\n",
    "        color=p[-1].get_color(),\n",
    "        ls=\"dotted\",\n",
    "        label=\"learn linear evolver\",\n",
    "    )\n",
    "\n",
    "    # reconstruct each point using SVD\n",
    "    ax[i].plot(\n",
    "        tvals,\n",
    "        recon_each[:, nix],\n",
    "        color=p[-1].get_color(),\n",
    "        ls=\"dashed\",\n",
    "        label=\"reconstruct each time point\",\n",
    "    )\n",
    "    ax[i].set_ylabel(ptype)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192bec58",
   "metadata": {},
   "source": [
    "## Study neighborhoods in latent space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f20ae4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 256\n",
    "svd = sklearn.decomposition.TruncatedSVD(n_components=L)\n",
    "svd.fit(train_mat)\n",
    "\n",
    "proj = svd.transform(train_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e03b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dist = [0.0]\n",
    "gaps = np.arange(11)\n",
    "for gap in gaps[1:]:\n",
    "    mean_dist.append(\n",
    "        np.linalg.norm(train_mat[:-gap, :] - train_mat[gap:, :], axis=1).mean()\n",
    "    )\n",
    "plt.plot(gaps, mean_dist, marker=\"o\")\n",
    "plt.xticks(gaps)\n",
    "plt.xlabel(\"time step delta\")\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Mean orig space distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec24b7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_dist = [0.0]\n",
    "gaps = np.arange(11)\n",
    "for gap in gaps[1:]:\n",
    "    mean_dist.append(np.linalg.norm(proj[:-gap, :] - proj[gap:, :], axis=1).mean())\n",
    "plt.plot(gaps, mean_dist, marker=\"o\")\n",
    "plt.xticks(gaps)\n",
    "plt.xlabel(\"time step delta\")\n",
    "plt.grid(True)\n",
    "plt.ylabel(\"Mean latent space distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f247d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gap in (1, 2, 3, 4, 5, 10):\n",
    "    log_dist = np.log(np.linalg.norm(proj[:-gap] - proj[gap:], axis=1))\n",
    "    mu, sig = scipy.stats.norm.fit(log_dist)\n",
    "    print(f\"{mu=:.2f}, {sig=:.2f}\")\n",
    "    xvs = np.linspace(log_dist.min(), log_dist.max(), 100)\n",
    "    p = plt.hist(log_dist, histtype=\"step\", label=f\"{gap} steps\", density=True)\n",
    "    plt.plot(\n",
    "        xvs,\n",
    "        scipy.stats.norm.pdf(xvs, mu, sig),\n",
    "        color=p[-1][0].get_edgecolor(),\n",
    "        ls=\"dashed\",\n",
    "    )\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a498875",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = sklearn.neighbors.BallTree(proj)\n",
    "dist, ninds = tree.query(proj, k=10, return_distance=True, sort_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12263f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = ninds[:, 1:] - ninds[:, :1]\n",
    "# order = np.argsort(dt, axis=1)\n",
    "for i in np.unique(np.random.randint(0, 3000, size=5)):\n",
    "    plt.scatter(\n",
    "        dt[i],\n",
    "        dist[i][1:],\n",
    "    )\n",
    "plt.ylabel(\"latent space distance\")\n",
    "plt.xlabel(\"time step separation\")\n",
    "plt.xlim(-3000, 3000)\n",
    "plt.ylim(0, None)\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9cb4c71",
   "metadata": {},
   "source": [
    "## Add in the stimulus that we forgot about\n",
    "\n",
    "Don't do SVD, just optimize a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abaaaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Latent space for neural activity\n",
    "\n",
    "import itertools\n",
    "\n",
    "L = 256\n",
    "\n",
    "activity_tensor = torch.tensor(train_mat).to(device)\n",
    "stim_tensor = torch.tensor(train_stimulus[:, :1736]).to(device)\n",
    "\n",
    "train_tensor = torch.concatenate([activity_tensor, stim_tensor], dim=-1)\n",
    "encoder = torch.nn.Linear(in_features=train_tensor.shape[1], out_features=L).to(device)\n",
    "\n",
    "decoder_activity = torch.nn.Linear(\n",
    "    in_features=L, out_features=activity_tensor.shape[1]\n",
    ").to(device)\n",
    "\n",
    "evolver = torch.nn.Linear(in_features=L, out_features=L).to(device)\n",
    "\n",
    "\n",
    "@torch.compile(fullgraph=True, mode=\"reduce-overhead\")\n",
    "def compute_loss(train_tensor, activity_tensor):\n",
    "    proj_act = encoder(train_tensor)\n",
    "    evolved = evolver(proj_act)\n",
    "    recon_next_time_step = decoder_activity(evolved)\n",
    "\n",
    "    recon = decoder_activity(proj_act)\n",
    "\n",
    "    recon_loss = torch.nn.MSELoss()(recon, activity_tensor)\n",
    "    evolve_loss = torch.nn.MSELoss()(recon_next_time_step[:-1], activity_tensor[1:])\n",
    "    return evolve_loss, recon_loss\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    list(\n",
    "        itertools.chain(\n",
    "            encoder.parameters(), decoder_activity.parameters(), evolver.parameters()\n",
    "        )\n",
    "    ),\n",
    "    lr=1e-5,\n",
    ")\n",
    "\n",
    "# train_loop(evolve_mat, train_proj, optimizer)\n",
    "loop = tqdm.trange(10_000, ncols=100)\n",
    "for t in loop:\n",
    "    evolve_loss, recon_loss = compute_loss(train_tensor, activity_tensor)\n",
    "    loss = evolve_loss + recon_loss\n",
    "    loop.set_postfix(loss=loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d70074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_loop(evolve_mat, train_proj, optimizer)\n",
    "loop = tqdm.trange(10_000, ncols=100)\n",
    "for t in loop:\n",
    "    evolve_loss, recon_loss = compute_loss(train_tensor, activity_tensor)\n",
    "    loss = evolve_loss + recon_loss\n",
    "    loop.set_postfix(evolve=evolve_loss.item(), recon=recon_loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec69dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_act = encoder(train_tensor)\n",
    "recon_each = decoder_activity(proj_act).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbd4948",
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 50\n",
    "t0 = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74f2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "p0 = proj_act[t0 : t0 + 1]\n",
    "\n",
    "results = [p0]\n",
    "\n",
    "for t in range(T):\n",
    "    p1 = evolver(results[-1])\n",
    "    results.append(p1)\n",
    "\n",
    "pred_trace = decoder_activity(torch.concatenate(results, dim=0)).detach().cpu().numpy()\n",
    "act_trace = train_mat[t0 : t0 + T + 1]\n",
    "recon_trace = recon_each[t0 : t0 + T + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497d20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_neuron_types = np.sort(np.random.choice(neuron_type_name, 10))\n",
    "# ['R1', 'R7', 'C2', 'Mi11', 'Tm1', 'Tm4', 'Tm30']\n",
    "\n",
    "_, ax = plt.subplots(len(plot_neuron_types), 1, figsize=(8, 12), sharex=True)\n",
    "tvals = np.arange(t0, t0 + T + 1)\n",
    "rng = np.random.default_rng(seed=123)\n",
    "picks = [rng.choice(nixs) for nixs in neuron_ixs_by_type]\n",
    "\n",
    "for i, ptype in enumerate(plot_neuron_types):\n",
    "    nix = picks[neuron_type_index[ptype]]\n",
    "    true_trace = train_mat[t0 : t0 + T + 1, nix]\n",
    "    p = ax[i].plot(tvals, true_trace)\n",
    "    ax[i].set_ylim(true_trace.min() * 0.8, true_trace.max() * 1.2)\n",
    "    # time evolve\n",
    "    ax[i].plot(\n",
    "        tvals,\n",
    "        pred_trace[:, nix],\n",
    "        color=p[-1].get_color(),\n",
    "        ls=\"dotted\",\n",
    "        label=\"learn linear evolver\",\n",
    "    )\n",
    "\n",
    "    ax[i].plot(\n",
    "        tvals,\n",
    "        recon_trace[:, nix],\n",
    "        color=p[-1].get_color(),\n",
    "        ls=\"dashed\",\n",
    "        marker=\".\",\n",
    "        label=\"reconstruct each time point\",\n",
    "    )\n",
    "    ax[i].set_ylabel(ptype)\n",
    "\n",
    "plt.subplots_adjust(hspace=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187dec59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we predicted a constant?\n",
    "err_constant = np.sqrt(\n",
    "    np.power(train_mat[t0 : t0 + 1] - train_mat[t0 : t0 + T + 1, :], 2).mean(axis=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a8864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_t = np.sqrt(np.power(pred_trace - train_mat[t0 : t0 + T + 1, :], 2).mean(axis=1))\n",
    "plt.plot(delta_t, label=\"rms error\")\n",
    "plt.plot(err_constant, ls=\"dotted\", label=\"rms error x(t) = x(t0)\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"time\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd01b124",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (neural-graph-linux)",
   "language": "python",
   "name": "neural-graph-linux"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
