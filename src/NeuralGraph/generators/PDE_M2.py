
import torch
import torch.nn as nn


def mlp(sizes, activation=nn.Tanh, final_activation=None):
    """Build a simple feedforward MLP."""
    layers = []
    for i in range(len(sizes) - 1):
        layers.append(nn.Linear(sizes[i], sizes[i + 1]))
        if i < len(sizes) - 2:
            layers.append(activation())
        elif final_activation is not None:
            layers.append(final_activation())
    return nn.Sequential(*layers)


class PDE_M2(nn.Module):
    """Stoichiometric kinetics ODE with external rate modulation.

    Extends PDE_M1 by allowing an external signal (e.g. a movie mapped onto
    metabolite positions) to modulate the per-reaction rate constants.

    The external input lives in x[:, 4] (one value per metabolite).  For each
    reaction j the modulation factor is the **mean external input across its
    substrate metabolites**, analogous to how PDE_N4 multiplies the synaptic
    message by the external input at the post-synaptic neuron.

    Modulation modes (set via ``config.simulation.external_input_mode``):
      - ``"multiplicative_substrate"``:  modulate rate via mean external input
            at substrate (reactant) metabolites of each reaction
      - ``"multiplicative_product"``:    modulate rate via mean external input
            at product metabolites of each reaction
      - ``"additive"``:        dx_i/dt += external_input_i   (direct flux)
      - ``"none"``:            identical to PDE_M1

    X tensor layout:
      x[:, 0]   = index (metabolite ID)
      x[:, 1:3] = positions (x, y)
      x[:, 3]   = concentration
      x[:, 4]   = external_input (modulation signal)
      x[:, 5]   = 0 (unused)
      x[:, 6]   = metabolite_type
      x[:, 7]   = 0 (unused)
    """

    def __init__(self, config=None, stoich_graph=None, device=None):
        super().__init__()

        n_met = config.simulation.n_metabolites
        n_rxn = config.simulation.n_reactions
        hidden = config.graph_model.hidden_dim
        msg_dim = config.graph_model.output_size

        self.n_met = n_met
        self.n_rxn = n_rxn
        self.device = device
        self.external_input_mode = getattr(
            config.simulation, 'external_input_mode', 'none'
        )
        self._debug_counter = 0

        print(f'[PDE_M2 __init__] external_input_mode = "{self.external_input_mode}"')
        print(f'[PDE_M2 __init__] n_met={n_met}, n_rxn={n_rxn}, hidden={hidden}, msg_dim={msg_dim}')

        # learnable MLPs
        self.msg_mlp = mlp([2, hidden, msg_dim], activation=nn.Tanh)
        self.rate_mlp = mlp([msg_dim, hidden, 1], activation=nn.Tanh)
        self.softplus = nn.Softplus(beta=1.0)

        # per-reaction rate constants: log-uniform in [0.01, 10]
        log_k = torch.empty(n_rxn)
        log_k.uniform_(-2.0, 1.0)
        self.log_k = nn.Parameter(log_k)

        # store stoichiometric graph (fixed, not learned)
        (met_sub, rxn_sub, sto_sub) = stoich_graph['sub']
        (met_all, rxn_all, sto_all) = stoich_graph['all']

        self.register_buffer('met_sub', met_sub)
        self.register_buffer('rxn_sub', rxn_sub)
        self.register_buffer('sto_sub', sto_sub)
        self.register_buffer('met_all', met_all)
        self.register_buffer('rxn_all', rxn_all)
        self.register_buffer('sto_all', sto_all)

        # pre-compute number of substrates per reaction for averaging
        n_sub_per_rxn = torch.zeros(n_rxn, dtype=torch.float32)
        n_sub_per_rxn.index_add_(0, rxn_sub, torch.ones_like(rxn_sub, dtype=torch.float32))
        n_sub_per_rxn.clamp_(min=1.0)
        self.register_buffer('n_sub_per_rxn', n_sub_per_rxn)

        # extract product edges from the 'all' graph (positive stoichiometry)
        prod_mask = sto_all > 0
        met_prod = met_all[prod_mask]
        rxn_prod = rxn_all[prod_mask]
        self.register_buffer('met_prod', met_prod)
        self.register_buffer('rxn_prod', rxn_prod)

        # pre-compute number of products per reaction for averaging
        n_prod_per_rxn = torch.zeros(n_rxn, dtype=torch.float32)
        n_prod_per_rxn.index_add_(0, rxn_prod, torch.ones_like(rxn_prod, dtype=torch.float32))
        n_prod_per_rxn.clamp_(min=1.0)
        self.register_buffer('n_prod_per_rxn', n_prod_per_rxn)

        self.p = torch.zeros(1)

    def forward(self, data=None, has_field=False, frame=None, dt=None):
        """Compute dx/dt for all metabolites.

        Parameters
        ----------
        dt : float, optional
            Integration time step. When provided, reaction rates are flux-
            limited so that no substrate concentration goes negative in one
            Euler step.

        Returns
        -------
        dxdt : Tensor of shape (n_met, 1)
        """
        x = data.x
        concentrations = x[:, 3]
        external_input = x[:, 4]

        do_print = (self._debug_counter % 500 == 0)

        if do_print:
            print(f'\n[PDE_M2 forward] step {self._debug_counter}')
            print(f'  external_input_mode = "{self.external_input_mode}"')
            print(f'  concentrations: min={concentrations.min():.4f}  max={concentrations.max():.4f}  mean={concentrations.mean():.4f}')
            print(f'  external_input: min={external_input.min():.4f}  max={external_input.max():.4f}  mean={external_input.mean():.4f}  nonzero={(external_input != 0).sum().item()}/{external_input.shape[0]}')

        # 1. gather substrate concentrations and stoichiometric coefficients
        x_src = concentrations[self.met_sub].unsqueeze(-1)
        s_abs = self.sto_sub.unsqueeze(-1)
        msg_in = torch.cat([x_src, s_abs], dim=-1)

        # 2. compute messages
        msg = self.msg_mlp(msg_in)

        # 3. aggregate messages per reaction
        h_rxn = torch.zeros(self.n_rxn, msg.shape[1], dtype=msg.dtype, device=msg.device)
        h_rxn.index_add_(0, self.rxn_sub, msg)

        # 4. compute base reaction rates
        k = torch.pow(10.0, self.log_k)
        base_v = self.softplus(self.rate_mlp(h_rxn).squeeze(-1))

        if do_print:
            print(f'  k (rate constants): min={k.min():.4f}  max={k.max():.4f}  mean={k.mean():.4f}')
            print(f'  base_v (softplus): min={base_v.min():.4f}  max={base_v.max():.4f}  mean={base_v.mean():.4f}')
            print(f'  k*base_v (unmodulated): min={(k*base_v).min():.4f}  max={(k*base_v).max():.4f}  mean={(k*base_v).mean():.4f}')

        # 5. apply external modulation
        if self.external_input_mode == "multiplicative_substrate":
            ext_src = external_input[self.met_sub]
            ext_agg = torch.zeros(self.n_rxn, dtype=ext_src.dtype, device=ext_src.device)
            ext_agg.index_add_(0, self.rxn_sub, ext_src)
            ext_mean = ext_agg / self.n_sub_per_rxn
            v = k * ext_mean * base_v
            if do_print:
                print(f'  [multiplicative_substrate] ACTIVE')
                print(f'    ext_src (per substrate edge): min={ext_src.min():.4f}  max={ext_src.max():.4f}  mean={ext_src.mean():.4f}  nonzero={( ext_src != 0).sum().item()}/{ext_src.shape[0]}')
                print(f'    ext_agg (sum per rxn): min={ext_agg.min():.4f}  max={ext_agg.max():.4f}  mean={ext_agg.mean():.4f}')
                print(f'    n_sub_per_rxn: min={self.n_sub_per_rxn.min():.1f}  max={self.n_sub_per_rxn.max():.1f}')
                print(f'    ext_mean (avg per rxn): min={ext_mean.min():.4f}  max={ext_mean.max():.4f}  mean={ext_mean.mean():.4f}  std={ext_mean.std():.4f}')
                print(f'    v = k*ext_mean*base_v: min={v.min():.6f}  max={v.max():.6f}  mean={v.mean():.6f}')
                v_unmod = k * base_v
                ratio = v / (v_unmod + 1e-12)
                print(f'    modulation ratio v/v_unmod: min={ratio.min():.4f}  max={ratio.max():.4f}  mean={ratio.mean():.4f}  std={ratio.std():.4f}')
        elif self.external_input_mode == "multiplicative_product":
            ext_src = external_input[self.met_prod]
            ext_agg = torch.zeros(self.n_rxn, dtype=ext_src.dtype, device=ext_src.device)
            ext_agg.index_add_(0, self.rxn_prod, ext_src)
            ext_mean = ext_agg / self.n_prod_per_rxn
            v = k * ext_mean * base_v
            if do_print:
                print(f'  [multiplicative_product] ACTIVE')
                print(f'    ext_mean: min={ext_mean.min():.4f}  max={ext_mean.max():.4f}  mean={ext_mean.mean():.4f}')
                print(f'    v: min={v.min():.6f}  max={v.max():.6f}')
        else:
            v = k * base_v
            if do_print:
                print(f'  [NO modulation] mode="{self.external_input_mode}" -> falling through to else')
                print(f'    v = k*base_v: min={v.min():.6f}  max={v.max():.6f}')

        # 6. flux limiting: scale rates so no substrate goes negative
        if dt is not None and dt > 0:
            v = self._flux_limit(v, concentrations, dt)

        # 7. compute dx/dt via stoichiometric matrix
        contrib = self.sto_all * v[self.rxn_all]
        dxdt = torch.zeros(self.n_met, dtype=contrib.dtype, device=contrib.device)
        dxdt.index_add_(0, self.met_all, contrib)

        if do_print:
            print(f'  dxdt (before additive): min={dxdt.min():.6f}  max={dxdt.max():.6f}  mean={dxdt.mean():.6f}  absmax={dxdt.abs().max():.6f}')

        # 8. additive external input (direct flux injection)
        if self.external_input_mode == "additive":
            dxdt = dxdt + external_input

        if do_print:
            print(f'  dxdt (final): min={dxdt.min():.6f}  max={dxdt.max():.6f}  mean={dxdt.mean():.6f}')

        self._debug_counter += 1

        return dxdt.unsqueeze(-1)

    def _flux_limit(self, v, concentrations, dt):
        """Scale reaction rates so no substrate is over-consumed in one step.

        For each metabolite, compute total planned consumption across all
        reactions.  If it exceeds the available concentration, scale all
        reaction rates by the tightest per-substrate constraint.
        """
        consumption = self.sto_sub * v[self.rxn_sub] * dt

        total_consumption = torch.zeros(
            self.n_met, dtype=v.dtype, device=v.device
        )
        total_consumption.index_add_(0, self.met_sub, consumption)

        met_scale = torch.ones(self.n_met, dtype=v.dtype, device=v.device)
        active = total_consumption > 1e-12
        met_scale[active] = torch.clamp(
            concentrations[active] / total_consumption[active], max=1.0
        )

        edge_scale = met_scale[self.met_sub]
        rxn_scale = torch.ones(self.n_rxn, dtype=v.dtype, device=v.device)
        rxn_scale.scatter_reduce_(
            0, self.rxn_sub, edge_scale, reduce='amin', include_self=True
        )

        return v * rxn_scale

    def get_rates(self, data):
        """Return reaction rates for diagnostics."""
        x = data.x
        concentrations = x[:, 3]
        external_input = x[:, 4]

        x_src = concentrations[self.met_sub].unsqueeze(-1)
        s_abs = self.sto_sub.unsqueeze(-1)
        msg_in = torch.cat([x_src, s_abs], dim=-1)
        msg = self.msg_mlp(msg_in)

        h_rxn = torch.zeros(self.n_rxn, msg.shape[1], dtype=msg.dtype, device=msg.device)
        h_rxn.index_add_(0, self.rxn_sub, msg)

        k = torch.pow(10.0, self.log_k)
        base_v = self.softplus(self.rate_mlp(h_rxn).squeeze(-1))

        if self.external_input_mode == "multiplicative_substrate":
            # Gather the external input value at each substrate metabolite
            # ext_src[e] = external_input of the metabolite on substrate edge e
            ext_src = external_input[self.met_sub]
            # Sum external inputs per reaction (scatter-add over substrate edges)
            ext_agg = torch.zeros(self.n_rxn, dtype=ext_src.dtype, device=ext_src.device)
            ext_agg.index_add_(0, self.rxn_sub, ext_src)
            # Average over the number of substrates of each reaction
            # ext_mean[j] = mean external input across substrates of reaction j
            ext_mean = ext_agg # / self.n_sub_per_rxn
            # Modulate rate: the movie signal scales enzyme activity
            v = k * ext_mean * base_v
        elif self.external_input_mode == "multiplicative_product":
            # Gather the external input value at each product metabolite
            ext_src = external_input[self.met_prod]
            # Sum external inputs per reaction (scatter-add over product edges)
            ext_agg = torch.zeros(self.n_rxn, dtype=ext_src.dtype, device=ext_src.device)
            ext_agg.index_add_(0, self.rxn_prod, ext_src)
            # Average over the number of products of each reaction
            ext_mean = ext_agg # / self.n_prod_per_rxn
            v = k * ext_mean * base_v
        else:
            v = k * base_v

        return v
