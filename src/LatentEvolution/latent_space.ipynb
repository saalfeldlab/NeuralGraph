{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1df7b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.jit\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.neighbors\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import polars as pl\n",
    "import scipy.stats\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e7efc40",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m torch.cuda.is_available()\n",
      "\u001b[31mAssertionError\u001b[39m: "
     ]
    }
   ],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_run_dir = \"/groups/saalfeld/home/kumarv4/repos/NeuralGraph/runs\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a91a4f0",
   "metadata": {},
   "source": [
    "# tinker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76a8062e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 0, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.rand((50, 100))\n",
    "inds = torch.unsqueeze(torch.tensor([10, 20, 30]), dim=1) + torch.unsqueeze(torch.arange(0), dim=0)\n",
    "a[inds, :].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d715317",
   "metadata": {},
   "source": [
    "## Analyze runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import yaml\n",
    "from LatentEvolution.latent import ModelParams, LatentModel\n",
    "from typing import Any, Dict, List, MutableMapping, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92adf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_code_prefix = \"checkpoint_20251118_20251118\"\n",
    "\n",
    "#fully qualified\n",
    "cand_dirs = glob.glob(f\"{base_run_dir}/{expt_code_prefix}*\")\n",
    "assert len(cand_dirs) == 1\n",
    "expt_code = os.path.basename(cand_dirs[0])\n",
    "print(expt_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9a6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cfg_path in Path(cand_dirs[0]).rglob(\"config.yaml\"):\n",
    "    print(cfg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data dir\n",
    "sim_dir = f\"{base_run_dir}/../graphs_data/fly/fly_N9_62_1/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887faaf6",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c879d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_run_dir = Path(cfg_path).parent\n",
    "\n",
    "with open(pick_run_dir / \"config.yaml\") as fin:\n",
    "    raw = yaml.safe_load(fin)\n",
    "model_params = ModelParams.model_validate(raw)\n",
    "\n",
    "# load model\n",
    "\n",
    "model = LatentModel(model_params).to(device)\n",
    "model.load_state_dict(torch.load(f\"{pick_run_dir}/model_final.pt\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45ff1e8",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cc287f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LatentEvolution.load_flyvis import SimulationResults, FlyVisSim\n",
    "sim_data = SimulationResults.load(f\"{sim_dir}x_list_0.npy\")\n",
    "neuron_data = sim_data.neuron_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b9a782",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = model_params.training.data_split\n",
    "train_mat, val_mat, _ = sim_data.split_column(FlyVisSim.VOLTAGE, split)\n",
    "stim_train, val_stim_mat, _ = sim_data.split_column(FlyVisSim.STIMULUS, split, keep_first_n_limit=1736)\n",
    "val_data = torch.tensor(val_mat, device=device)\n",
    "val_stim = torch.tensor(val_stim_mat, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1929c772",
   "metadata": {},
   "source": [
    "## Load flyvis connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827f1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wt = torch.load(f\"{sim_dir}/weights.pt\", map_location=\"cpu\").numpy()\n",
    "edge_index = torch.load(f\"{sim_dir}/edge_index.pt\", map_location=\"cpu\").numpy()\n",
    "voltage_rest = torch.load(f\"{sim_dir}/V_i_rest.pt\", map_location=\"cpu\").numpy()\n",
    "taus = torch.load(f\"{sim_dir}/taus.pt\", map_location=\"cpu\").numpy()\n",
    "# this is compatible with cedric's conventions\n",
    "# Note: this is the transpose of what is in the flyvis paper so don't be confused\n",
    "wmat = scipy.sparse.csr_matrix((wt, (edge_index[1], edge_index[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456effbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(wt, bins=np.linspace(-1, 1, 100))\n",
    "plt.axvline(0.0, color=\"k\")\n",
    "plt.yscale(\"log\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e22976e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute n hops to stimuli for each neuron\n",
    "from collections import deque\n",
    "\n",
    "visited = np.zeros(len(neuron_data.type), dtype=bool)\n",
    "nhops = np.full(len(neuron_data.type), np.inf, dtype=np.float32)\n",
    "stimuli_neurons = np.arange(1736)\n",
    "nhops[stimuli_neurons] = 0\n",
    "process = deque(stimuli_neurons.tolist())\n",
    "visited[stimuli_neurons] = True\n",
    "\n",
    "while process:\n",
    "    node = process.popleft()  # FIFO: process in distance order\n",
    "    state = nhops[node]\n",
    "    nbrs = wmat.indices[wmat.indptr[node]:wmat.indptr[node+1]]\n",
    "\n",
    "    for n in nbrs:\n",
    "        if not visited[n]:  # First time reaching n = shortest path\n",
    "            nhops[n] = state + 1\n",
    "            visited[n] = True\n",
    "            process.append(n)  # Add to back of queue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0552428",
   "metadata": {},
   "outputs": [],
   "source": [
    "ndf = pl.DataFrame(\n",
    "    {\n",
    "        \"t\": neuron_data.type,\n",
    "        \"n_in\": np.array((np.abs(wmat) != 0.).sum(axis=0))[0],\n",
    "        \"n_out\": np.array((np.abs(wmat) != 0.).sum(axis=1))[:, 0],\n",
    "        \"nhops\": nhops\n",
    "    }\n",
    ").join(\n",
    "    pl.DataFrame({\"name\": neuron_data.TYPE_NAMES}).with_row_index(\"t\").with_columns(pl.col(\"t\").cast(pl.UInt8)), on=\"t\", how=\"left\"\n",
    ")\n",
    "with pl.Config(tbl_rows=100):\n",
    "    print(ndf.group_by(\"name\").agg(pl.col(\"nhops\").filter(pl.col(\"n_in\") > 0).mean(), pl.len()).sort(\"name\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3d955",
   "metadata": {},
   "source": [
    "## Compute the jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev, vmap\n",
    "\n",
    "\n",
    "def model_combined(xs):\n",
    "    \"\"\"\n",
    "    xs: concatenated [x, s] of shape (13741 + 1736,)\n",
    "    \"\"\"\n",
    "    x = xs[:13741]\n",
    "    s = xs[13741:]\n",
    "    return model(x.unsqueeze(0), s.unsqueeze(0)).squeeze(0)\n",
    "x_points = np.zeros((10, 13741), dtype=np.float32)\n",
    "x_points[:, 0] = np.linspace(-20, 20, 10)\n",
    "x_points = torch.tensor(x_points, device=device)\n",
    "s_points = torch.zeros((10, 1736), device=device)\n",
    "# For multiple points\n",
    "jac_combined_all = vmap(lambda xs: jacrev(model_combined)(xs))(\n",
    "    torch.cat([x_points, s_points], dim=1)\n",
    ").detach().cpu().numpy()  # shape: (num_points, 13741, 15477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvals = np.random.choice(jac_combined_all[5].ravel(), 1000)\n",
    "evals = np.random.choice(jac_combined_all[5, edge_index[1], edge_index[0]], 1000)\n",
    "tvals = np.random.choice(wmat.data, 1000)\n",
    "plt.hist(rvals, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)\n",
    "plt.hist(evals, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)\n",
    "plt.hist(tvals*.02, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc1468",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = np.random.randint(0, edge_index.shape[1], 10000)\n",
    "plt.scatter(wt, jac_combined_all[5, edge_index[1], edge_index[0]], s=0.01, alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8806c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(disp_mat.ravel(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_mat = jac_combined_all[0, 0:217*2, 1736:1736 + 217*2]/.02\n",
    "plt.imshow(disp_mat , cmap=\"Greys_r\", vmax=0.3, vmin=0.0, extent=[1736, 1736+217*2, 217*2, 0])\n",
    "plt.xlabel(\"neurons\")\n",
    "plt.ylabel(\"neurons\")\n",
    "plt.title(\"Jacobian neuron-neuron (same subset)\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wmat[0:217+217, 1736:1736 + 217*2].todense(), cmap=\"Greys_r\", extent=[1736, 1736+217*2, 217*2, 0])\n",
    "plt.colorbar()\n",
    "plt.title(\"True weight matrix (subset)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519d88e2",
   "metadata": {},
   "source": [
    "## Multi-step rollout evolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2loydlyi9i4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evolve_n_steps(model, initial_state, stimulus, n_steps):\n",
    "    \"\"\"\n",
    "    Evolve the model by n time steps using the predicted state at each step.\n",
    "\n",
    "    Args:\n",
    "        model: The LatentModel to evolve\n",
    "        initial_state: Initial state tensor of shape (neurons,)\n",
    "        stimulus: Stimulus tensor of shape (T, stimulus_dim) where T >= n_steps\n",
    "        n_steps: Number of time steps to evolve\n",
    "\n",
    "    Returns:\n",
    "        predicted_trace: Tensor of shape (n_steps, neurons) with predicted states\n",
    "    \"\"\"\n",
    "    predicted_trace = []\n",
    "    current_state = initial_state\n",
    "\n",
    "    for t in range(n_steps):\n",
    "        # Get the stimulus for this time step\n",
    "        current_stimulus = stimulus[t:t+1]  # shape (1, stimulus_dim)\n",
    "\n",
    "        # Evolve by one step\n",
    "        next_state = model(current_state.unsqueeze(0), current_stimulus).squeeze(0)\n",
    "\n",
    "        predicted_trace.append(next_state)\n",
    "\n",
    "        # Use predicted state as input for next step\n",
    "        current_state = next_state\n",
    "\n",
    "    return torch.stack(predicted_trace, dim=0)\n",
    "\n",
    "\n",
    "def compare_traces(model, real_trace, stimulus, n_steps, start_idx=0):\n",
    "    \"\"\"\n",
    "    Compare real trace with predicted trace over n time steps.\n",
    "\n",
    "    Args:\n",
    "        model: The LatentModel to evolve\n",
    "        real_trace: Real state tensor of shape (T, neurons)\n",
    "        stimulus: Stimulus tensor of shape (T, stimulus_dim)\n",
    "        n_steps: Number of time steps to predict\n",
    "        start_idx: Starting index in the trace\n",
    "\n",
    "    Returns:\n",
    "        real_segment: Real trace segment of shape (n_steps, neurons)\n",
    "        predicted_segment: Predicted trace segment of shape (n_steps, neurons)\n",
    "        mse_per_step: MSE at each time step, shape (n_steps,)\n",
    "        cumulative_mse: Cumulative average MSE up to each time step, shape (n_steps,)\n",
    "    \"\"\"\n",
    "    # Get initial state\n",
    "    initial_state = real_trace[start_idx]\n",
    "\n",
    "    # Get stimulus segment\n",
    "    stimulus_segment = stimulus[start_idx:start_idx + n_steps]\n",
    "\n",
    "    # Get real trace segment (ground truth for the next n_steps)\n",
    "    real_segment = real_trace[start_idx + 1:start_idx + n_steps + 1]\n",
    "\n",
    "    # Predict n steps\n",
    "    predicted_segment = evolve_n_steps(model, initial_state, stimulus_segment, n_steps)\n",
    "\n",
    "    # Compute MSE per time step\n",
    "    mse_per_step = torch.pow(predicted_segment - real_segment, 2).mean(dim=1)\n",
    "\n",
    "    # Compute cumulative MSE\n",
    "    cumulative_mse = torch.cumsum(mse_per_step, dim=0) / torch.arange(1, n_steps + 1, device=mse_per_step.device)\n",
    "\n",
    "    return real_segment, predicted_segment, mse_per_step, cumulative_mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1la8mwwtaow",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Evolve for 50 time steps\n",
    "n_steps = 2000\n",
    "start_idx = 100  # Start from index 100 in the validation data\n",
    "\n",
    "real_segment, predicted_segment, mse_per_step, cumulative_mse = compare_traces(\n",
    "    model, val_data, val_stim[:, :1736], n_steps, start_idx\n",
    ")\n",
    "\n",
    "print(f\"Shape of real segment: {real_segment.shape}\")\n",
    "print(f\"Shape of predicted segment: {predicted_segment.shape}\")\n",
    "print(f\"Final MSE (averaged over all neurons): {mse_per_step[-1].item():.6f}\")\n",
    "print(f\"Final cumulative MSE: {cumulative_mse[-1].item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "u6n045etfem",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize MSE growth over time\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot MSE per time step\n",
    "axes[0].plot(mse_per_step.detach().cpu().numpy(), marker='o', markersize=3)\n",
    "axes[0].set_xlabel('Time Step')\n",
    "axes[0].set_ylabel('MSE (averaged over neurons)')\n",
    "axes[0].set_title('MSE at Each Time Step')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot cumulative MSE\n",
    "axes[1].plot(cumulative_mse.detach().cpu().numpy(), marker='o', markersize=3, color='orange')\n",
    "axes[1].set_xlabel('Time Step')\n",
    "axes[1].set_ylabel('Cumulative Average MSE')\n",
    "axes[1].set_title('Cumulative Average MSE Over Time')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zunsap9xz8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize traces for specific cell types\n",
    "# Cell types picked from GNN_PlotFigure.py line 4824\n",
    "target_cell_types = ['R1', 'R7', 'C2', 'Mi11', 'Tm1', 'Tm4', 'Tm30']\n",
    "\n",
    "# Get indices for each cell type\n",
    "neuron_indices = []\n",
    "for cell_type in target_cell_types:\n",
    "    # Find type index\n",
    "    type_idx = neuron_data.TYPE_NAMES.index(cell_type)\n",
    "    # Pick a random neuron from this type using neuron_data.indices_per_type\n",
    "    selected_neuron = np.random.choice(neuron_data.indices_per_type[type_idx])\n",
    "    neuron_indices.append(selected_neuron)\n",
    "\n",
    "# Plot traces\n",
    "num_neurons_to_plot = len(neuron_indices)\n",
    "fig, axes = plt.subplots(num_neurons_to_plot, 1, figsize=(18, 2.5 * num_neurons_to_plot))\n",
    "if num_neurons_to_plot == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, neuron_idx in enumerate(neuron_indices):\n",
    "    real_trace_cpu = real_segment[:, neuron_idx].detach().cpu().numpy()\n",
    "    pred_trace_cpu = predicted_segment[:, neuron_idx].detach().cpu().numpy()\n",
    "\n",
    "    # Get cell type name\n",
    "    cell_type_idx = neuron_data.type[neuron_idx]\n",
    "    cell_type_name = neuron_data.TYPE_NAMES[cell_type_idx]\n",
    "\n",
    "    axes[i].plot(real_trace_cpu, label='Real', linewidth=2, alpha=0.7)\n",
    "    axes[i].plot(pred_trace_cpu, label='Predicted', linewidth=2, alpha=0.7, linestyle='--')\n",
    "    axes[i].set_xlabel('Time Step')\n",
    "    axes[i].set_ylabel('Voltage')\n",
    "    axes[i].set_title(f'{cell_type_name} (neuron {neuron_idx})')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01042d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wmat[1736, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f823a325",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
