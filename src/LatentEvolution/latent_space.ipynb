{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df7b1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import os\n",
    "import itertools\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.jit\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sklearn.decomposition\n",
    "import sklearn.manifold\n",
    "import sklearn.neighbors\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import polars as pl\n",
    "import scipy.stats\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7efc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d715317",
   "metadata": {},
   "source": [
    "## Analyze runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d98ab79",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import yaml\n",
    "from LatentEvolution.latent import ModelParams, LatentModel\n",
    "from typing import Any, Dict, List, MutableMapping, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92adf4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_code = \"l1_reg_all\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58b6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw data dir\n",
    "sim_dir = \"/groups/saalfeld/home/kumarv4/repos/NeuralGraph/graphs_data/fly/fly_N9_62_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63275254",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def flatten_dict(\n",
    "    d: MutableMapping[str, Any], parent_key: str = \"\", sep: str = \".\"\n",
    ") -> Dict[str, Any]:\n",
    "    items: List[Tuple[str, Any]] = []\n",
    "    for k, v in d.items():\n",
    "        new_key = f\"{parent_key}{sep}{k}\" if parent_key else k\n",
    "        if isinstance(v, MutableMapping):\n",
    "            items.extend(flatten_dict(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n",
    "\n",
    "\n",
    "\n",
    "run_dir_base = Path(\"/groups/saalfeld/home/kumarv4/repos/NeuralGraph/runs\") / expt_code\n",
    "assert run_dir_base.exists()\n",
    "\n",
    "\n",
    "run_dirs = [Path(p) for p in glob.glob(f\"{run_dir_base}/*\")]\n",
    "configs = []\n",
    "metrics = []\n",
    "model_params = {}\n",
    "metric_keys = None\n",
    "for run_dir in run_dirs:\n",
    "    with open(run_dir / \"config.yaml\") as fin:\n",
    "        raw = yaml.safe_load(fin)\n",
    "    config = ModelParams.model_validate(raw)\n",
    "    model_params[run_dir] = config\n",
    "    raw_flat = flatten_dict(raw)\n",
    "\n",
    "    metrics_file = run_dir / \"final_metrics.yaml\"\n",
    "    # if not metrics_file.exists():\n",
    "    #     metrics.append({})\n",
    "    #     continue\n",
    "    configs.append(raw_flat)\n",
    "\n",
    "    with open(metrics_file) as fin:\n",
    "        raw = yaml.safe_load(fin)\n",
    "        metrics.append(raw)\n",
    "        if metric_keys is None:\n",
    "            metric_keys = sorted(raw.keys())\n",
    "        else:\n",
    "            assert metric_keys == sorted(raw.keys())\n",
    "\n",
    "assert metric_keys is not None, \"All runs failed\"\n",
    "\n",
    "config_df = pl.DataFrame(configs)\n",
    "config_cols = []\n",
    "for col in config_df.columns:\n",
    "    if config_df[col].unique().shape[0] > 1:\n",
    "        config_cols.append(col)\n",
    "config_cols.sort(key=lambda k: k.count(\".\"))\n",
    "\n",
    "\n",
    "metrics_df = pl.DataFrame(metrics, schema=metric_keys)\n",
    "\n",
    "df = pl.concat([config_df, metrics_df], how=\"horizontal\").with_columns(\n",
    "    pl.Series(\"run_dir\", run_dirs)\n",
    ").sort(config_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a476d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in df.rows(named=True):\n",
    "    run_dir = row[\"run_dir\"]\n",
    "    tdf = pl.read_csv(f\"{run_dir}/training_log.csv\")\n",
    "    plt.plot(tdf[\"val_loss\"], label=f\"l1 weight {row['encoder_params.l1_reg_loss']:.1e}\")\n",
    "plt.yscale(\"log\")\n",
    "plt.legend()\n",
    "plt.title(\"Val loss\")\n",
    "plt.ylim(None, 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887faaf6",
   "metadata": {},
   "source": [
    "# Analyze one model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c879d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab1d463",
   "metadata": {},
   "outputs": [],
   "source": [
    "pick_run_dirs = df.drop_nulls().filter(pl.col(\"encoder_params.l1_reg_loss\") == 0.0)[\"run_dir\", \"encoder_params.l1_reg_loss\", \"final_val_loss\"]\n",
    "print(pick_run_dirs)\n",
    "pick_run_dir = pick_run_dirs[\"run_dir\"][0]\n",
    "\n",
    "# load model\n",
    "\n",
    "model = LatentModel(model_params[pick_run_dir]).to(device)\n",
    "model.load_state_dict(torch.load(f\"{pick_run_dir}/model_final.pt\"))\n",
    "model.eval()\n",
    "with open(pick_run_dir / \"config.yaml\") as fin:\n",
    "    raw = yaml.safe_load(fin)\n",
    "config = ModelParams.model_validate(raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920f1975",
   "metadata": {},
   "source": [
    "## neuron traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46474d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_csv(f\"{pick_run_dir}/training_log.csv\")\n",
    "plt.plot(df[\"train_loss\"])\n",
    "plt.plot(df[\"val_loss\"])\n",
    "plt.yscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efaa7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from LatentEvolution.load_flyvis import SimulationResults, FlyVisSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3392a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_data = SimulationResults.load(f\"{sim_dir}x_list_0.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb8c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "split = config.training.data_split\n",
    "val_mat = sim_data[FlyVisSim.VOLTAGE][split.validation_start:split.validation_end]\n",
    "val_data = torch.tensor(val_mat, device=device)\n",
    "val_stim = torch.tensor(sim_data[FlyVisSim.STIMULUS][split.validation_start:split.validation_end], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07ce247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reconstruction\n",
    "\n",
    "proj = model.encoder(val_data)\n",
    "recon = model.decoder(proj).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039e035d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "index_to_name = {0: 'Am', 1: 'C2', 2: 'C3', 3: 'CT1(Lo1)', 4: 'CT1(M10)', 5: 'L1', 6: 'L2',\n",
    "    7: 'L3', 8: 'L4', 9: 'L5', 10: 'Lawf1', 11: 'Lawf2', 12: 'Mi1', 13: 'Mi10',\n",
    "    14: 'Mi11', 15: 'Mi12', 16: 'Mi13', 17: 'Mi14', 18: 'Mi15', 19: 'Mi2',\n",
    "    20: 'Mi3', 21: 'Mi4', 22: 'Mi9', 23: 'R1', 24: 'R2', 25: 'R3', 26: 'R4',\n",
    "    27: 'R5', 28: 'R6', 29: 'R7', 30: 'R8', 31: 'T1', 32: 'T2', 33: 'T2a',\n",
    "    34: 'T3', 35: 'T4a', 36: 'T4b', 37: 'T4c', 38: 'T4d', 39: 'T5a', 40: 'T5b',\n",
    "    41: 'T5c', 42: 'T5d', 43: 'Tm1', 44: 'Tm16', 45: 'Tm2', 46: 'Tm20', 47: 'Tm28',\n",
    "    48: 'Tm3', 49: 'Tm30', 50: 'Tm4', 51: 'Tm5Y', 52: 'Tm5a', 53: 'Tm5b',\n",
    "    54: 'Tm5c', 55: 'Tm9', 56: 'TmY10', 57: 'TmY13', 58: 'TmY14', 59: 'TmY15',\n",
    "    60: 'TmY18', 61: 'TmY3', 62: 'TmY4', 63: 'TmY5a', 64: 'TmY9'\n",
    "}\n",
    "neuron_type_name = [\n",
    "    \"Am\", \"C2\", \"C3\", \"CT1(Lo1)\", \"CT1(M10)\",\n",
    "    \"L1\", \"L2\", \"L3\", \"L4\", \"L5\", \"Lawf1\", \"Lawf2\",\n",
    "    \"Mi1\", \"Mi10\", \"Mi11\", \"Mi12\", \"Mi13\", \"Mi14\", \"Mi15\", \"Mi2\", \"Mi3\", \"Mi4\", \"Mi9\",\n",
    "    \"R1\", \"R2\", \"R3\", \"R4\", \"R5\", \"R6\", \"R7\", \"R8\",\n",
    "    \"T1\", \"T2\", \"T2a\", \"T3\", \"T4a\", \"T4b\", \"T4c\", \"T4d\", \"T5a\", \"T5b\", \"T5c\", \"T5d\",\n",
    "    \"Tm1\", \"Tm16\", \"Tm2\", \"Tm20\", \"Tm28\", \"Tm3\", \"Tm30\", \"Tm4\", \"Tm5Y\",\n",
    "    \"Tm5a\", \"Tm5b\", \"Tm5c\", \"Tm9\", \"TmY10\", \"TmY13\", \"TmY14\",\n",
    "    \"TmY15\", \"TmY18\", \"TmY3\", \"TmY4\", \"TmY5a\", \"TmY9\"\n",
    "]\n",
    "neuron_type_index = {t: i for i, t in enumerate(neuron_type_name)}\n",
    "\n",
    "def compute_ixs_per_type(neuron_types):\n",
    "    \"\"\"Compute indices corresponding to each neuron type.\"\"\"\n",
    "    order = np.argsort(neuron_types)\n",
    "    uniq_types, start_index = np.unique(neuron_types[order], return_index=True)\n",
    "    num_neuron_types = len(uniq_types)\n",
    "    assert (uniq_types == np.arange(num_neuron_types)).all(), \"breaks assumptions\"\n",
    "    breaks = np.zeros(len(uniq_types)+1, dtype=np.int64)\n",
    "    breaks[:-1] = start_index\n",
    "    breaks[-1] = len(neuron_types)\n",
    "    return [\n",
    "        order[breaks[i]:breaks[i+1]] for i in range(num_neuron_types)\n",
    "    ]\n",
    "neuron_types = sim_data[FlyVisSim.TYPE][0]\n",
    "neuron_ixs_by_type = compute_ixs_per_type(neuron_types)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083b70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_stim.shape, val_data.shape\n",
    "evolved = model(val_data, val_stim[:, :1736]).detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff164001",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_neuron_types = np.sort(np.random.choice(neuron_type_name, 10))\n",
    "# plot_neuron_types = ['R1', 'R7', 'C2', 'Mi11', 'Tm1', 'Tm4', 'Tm30']\n",
    "\n",
    "_, ax = plt.subplots(len(plot_neuron_types), 1, figsize=(8, 16), sharex=True)\n",
    "t0 = 0\n",
    "T = val_mat.shape[0]\n",
    "tvals = np.arange(t0, t0 + T)\n",
    "rng = np.random.default_rng(seed=123)\n",
    "picks = [rng.choice(nixs) for nixs in neuron_ixs_by_type]\n",
    "\n",
    "for i, ptype in enumerate(plot_neuron_types):\n",
    "    nix = picks[neuron_type_index[ptype]]\n",
    "    true_trace = val_mat[:, nix]\n",
    "    p = ax[i].plot(\n",
    "        tvals,\n",
    "        recon[:, nix],\n",
    "        ls=\"dashed\",\n",
    "        # marker=\".\",\n",
    "        label=\"reconstruct each time point\",\n",
    "    )\n",
    "\n",
    "    ax[i].plot(tvals, true_trace, lw=3, color=p[-1].get_color(), alpha=0.2)\n",
    "    ylim = ax[i].get_ylim()\n",
    "    yc = 0.5*(ylim[0] + ylim[1])\n",
    "    ylen = ylim[1] - ylim[0]\n",
    "    if ylen < 2:\n",
    "        ylim = (yc-1, yc+1)\n",
    "\n",
    "\n",
    "    # # ax[i].set_ylim(1, 2)\n",
    "    # # # time evolve\n",
    "    # ax[i].plot(\n",
    "    #     tvals,\n",
    "    #     evolved[:, nix],\n",
    "    #     color=p[-1].get_color(),\n",
    "    #     ls=\"dotted\",\n",
    "    #     label=\"learn linear evolver\",\n",
    "    # )\n",
    "\n",
    "\n",
    "    ax[i].set_ylim(*ylim)\n",
    "    ax[i].set_ylabel(ptype)\n",
    "plt.xlim(0, 100)\n",
    "plt.subplots_adjust(hspace=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58365642",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evolve multiple time steps\n",
    "\n",
    "\n",
    "# go to latent space\n",
    "proj_stim = model.stimulus_encoder(val_stim[:, :1736])\n",
    "_, stim_dim = proj_stim.shape\n",
    "proj = model.encoder(val_data)\n",
    "evolver_input = torch.concatenate([proj, proj_stim], dim=1)\n",
    "offset = 0\n",
    "evolver_outputs = [proj]\n",
    "for i in range(5):\n",
    "    evolver_output = model.evolver(evolver_input)\n",
    "    evolver_input[:, :] = evolver_output\n",
    "    evolver_input[:, -stim_dim:] = proj_stim\n",
    "    evolver_outputs.append(evolver_output[:, :-stim_dim])\n",
    "\n",
    "evolver_outputs = torch.stack(evolver_outputs, dim=0)\n",
    "neuron_outputs = model.decoder(evolver_outputs.reshape((-1, 256))).reshape((6, -1, 13741))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a3637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_val = np.diff(val_mat, axis=0)\n",
    "pred_delta = evolved[:-1] - val_mat[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a293a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmin, vmax = delta_val.min(), delta_val.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c791dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins=50\n",
    "bins = np.linspace(np.floor(vmin), np.ceil(vmax), nbins+1)\n",
    "mps = 0.5*(bins[1:] + bins[:-1])\n",
    "ixs = np.searchsorted(bins, delta_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26f94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "den = np.bincount(ixs.ravel(), minlength=nbins+1)\n",
    "num = np.bincount(ixs.ravel(), weights=pred_delta.ravel(), minlength=nbins+1)\n",
    "num2 = np.bincount(ixs.ravel(), weights=np.power(pred_delta.ravel(), 2), minlength=nbins+1)\n",
    "mean = num/den\n",
    "err2 = num2/den - num**2 / den**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7936d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.sqrt(err2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17042bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(bins, mean, yerr=sigma, marker=\".\", capsize=3)\n",
    "plt.xlabel(\"True change t->t+1\")\n",
    "plt.ylabel(\"Predicted change t->t+1\")\n",
    "plt.plot([-5, 5], [-5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4bf7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bins, den / den.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0044979",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj1 = proj.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c3d955",
   "metadata": {},
   "source": [
    "## Compute the jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114d1643",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wt = torch.load(f\"{sim_dir}/weights.pt\", map_location=\"cpu\").numpy()\n",
    "edge_index = torch.load(f\"{sim_dir}/edge_index.pt\", map_location=\"cpu\").numpy()\n",
    "voltage_rest = torch.load(f\"{sim_dir}/V_i_rest.pt\", map_location=\"cpu\").numpy()\n",
    "taus = torch.load(f\"{sim_dir}/taus.pt\", map_location=\"cpu\").numpy()\n",
    "wmat = scipy.sparse.csc_matrix((wt, (edge_index[0], edge_index[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b8e16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.func import jacrev, vmap\n",
    "\n",
    "\n",
    "def model_combined(xs):\n",
    "    \"\"\"\n",
    "    xs: concatenated [x, s] of shape (13741 + 1736,)\n",
    "    \"\"\"\n",
    "    x = xs[:13741]\n",
    "    s = xs[13741:]\n",
    "    return model(x.unsqueeze(0), s.unsqueeze(0)).squeeze(0)\n",
    "x_points = np.zeros((10, 13741), dtype=np.float32)\n",
    "x_points[:, 0] = np.linspace(-20, 20, 10)\n",
    "x_points = torch.tensor(x_points, device=device)\n",
    "s_points = torch.zeros((10, 1736), device=device)\n",
    "# For multiple points\n",
    "jac_combined_all = vmap(lambda xs: jacrev(model_combined)(xs))(\n",
    "    torch.cat([x_points, s_points], dim=1)\n",
    ").detach().cpu().numpy()  # shape: (num_points, 13741, 15477)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91a5c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "rvals = np.random.choice(jac_combined_all[5].ravel(), 1000)\n",
    "evals = np.random.choice(jac_combined_all[5, edge_index[1], edge_index[0]], 1000)\n",
    "tvals = np.random.choice(wmat.data, 1000)\n",
    "plt.hist(rvals, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)\n",
    "plt.hist(evals, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)\n",
    "plt.hist(tvals*.02, bins=np.linspace(-0.02, 0.02, 51), alpha=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e66c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "disp_mat = jac_combined_all[5, 0:217, 1736:1736 + 217]\n",
    "plt.imshow(disp_mat , cmap=\"Greys_r\")\n",
    "plt.xlabel(\"neurons\")\n",
    "plt.ylabel(\"neurons\")\n",
    "plt.title(\"Jacobian\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3f9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wmat[217:217+217, 1736:1736 + 217].todense(), cmap=\"Greys_r\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519d88e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
