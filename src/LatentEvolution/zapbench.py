"""load zapbench calcium data and interpolate staggered observations.

two paths are provided:
- dense path: zarr -> (num_bins, N) dense matrix -> cummax/cummin interpolation
- sparse path: zarr -> (N, K) sparse representation -> searchsorted interpolation

the sparse path is preferred: 22x faster transfer, 3.3x faster interp,
3.4x less peak gpu memory at 2.6% observed density.
"""

import numpy as np
import tensorstore as ts
import torch


# ---------------------------------------------------------------------------
# zarr i/o helpers
# ---------------------------------------------------------------------------

def _make_kvstore(path: str) -> dict:
    """build tensorstore kvstore spec from a local or gs:// path."""
    if path.startswith("gs://"):
        without_scheme = path[len("gs://"):]
        bucket, _, prefix = without_scheme.partition("/")
        return {"driver": "gcs", "bucket": bucket, "path": prefix}
    return {"driver": "file", "path": path}


def _open_zarr(path: str) -> ts.TensorStore:
    """open a zarr array via tensorstore (local, NFS, or GCS).

    tries zarr v2 first, falls back to zarr v3 if v2 metadata is missing.
    """
    kvstore = _make_kvstore(path)
    try:
        return ts.open({"driver": "zarr", "kvstore": kvstore}).result()
    except ValueError:
        return ts.open({"driver": "zarr3", "kvstore": kvstore}).result()


def _load_zarr_arrays(
    traces_path: str,
    acq_path: str,
    time_slice: slice | None,
) -> tuple[np.ndarray, np.ndarray, int]:
    """read traces and acq from zarr, return (T, N) arrays.

    shared by load_staggered_activity and load_sparse_activity.
    """
    traces_store = _open_zarr(traces_path)
    acq_store = _open_zarr(acq_path)

    # acq is stored as (N, T), read and transpose to (T, N)
    if time_slice is not None:
        traces_np = traces_store[time_slice, :].read().result()
        acq_np = np.asarray(acq_store[:, time_slice].read().result()).T
    else:
        traces_np = traces_store.read().result()
        acq_np = np.asarray(acq_store.read().result()).T

    T, N = traces_np.shape
    assert acq_np.shape == (T, N), (
        f"traces shape {traces_np.shape} != acq shape {acq_np.shape}"
    )
    return np.asarray(traces_np), acq_np, T


def _compute_bin_indices(
    acq_np: np.ndarray,
    T: int,
    bin_size_ms: float,
    frame_period_ms: float,
) -> tuple[np.ndarray, int]:
    """compute bin indices from acquisition offsets.

    returns:
        bin_indices: (T, N) int64 array of bin indices, clamped to [0, num_bins-1].
        num_bins: total number of output time bins.
    """
    num_bins = int(np.ceil(T * frame_period_ms / bin_size_ms))
    frame_times = np.arange(T, dtype=np.float64) * frame_period_ms
    time_ms = frame_times[:, np.newaxis] + np.asarray(acq_np, dtype=np.float64)
    bin_indices = np.floor(time_ms / bin_size_ms).astype(np.int64)
    np.clip(bin_indices, 0, num_bins - 1, out=bin_indices)
    return bin_indices, num_bins


# ---------------------------------------------------------------------------
# dense path: zarr -> (num_bins, N) dense matrix -> cummax/cummin
# ---------------------------------------------------------------------------

def load_staggered_activity(
    traces_path: str,
    acq_path: str,
    bin_size_ms: float,
    frame_period_ms: float,
    time_slice: slice | None = None,
) -> tuple[torch.Tensor, torch.Tensor]:
    """load traces and acquisition timestamps, bin into a staggered matrix.

    each neuron is observed at irregular times given by per-frame offsets
    in acq. time within the loaded window is:

        time[t, n] = t * frame_period_ms + acq[t, n]

    we quantize these into discrete bins of bin_size_ms and place trace
    values into a (num_bins, N) matrix. each bin contains at most one
    observation per neuron. unobserved entries are NaN.

    the output size is deterministic: num_bins = ceil(T * frame_period_ms
    / bin_size_ms), independent of the actual offset values.

    args:
        traces_path: path to zarr array of shape (T, N), calcium traces.
            local/NFS path or gs:// URI.
        acq_path: path to zarr array of shape (T, N), offset timestamps
            in ms within each frame.
            local/NFS path or gs:// URI.
        bin_size_ms: bin width in milliseconds (e.g. 20.0).
        frame_period_ms: nominal interval between frames in ms.
        time_slice: optional slice along the T (sample) axis to load
            a subset of the data.

    returns:
        staggered: (num_bins, N) float32 cpu tensor. entry (b, n) is the
            trace value for neuron n in time bin b, or NaN if neuron n
            was not observed in that bin.
        observed: (num_bins, N) bool cpu tensor. True where a real
            observation exists.
    """
    traces_store = _open_zarr(traces_path)
    acq_store = _open_zarr(acq_path)

    # acq is stored as (N, T), read and transpose to (T, N)
    if time_slice is not None:
        traces_np = traces_store[time_slice, :].read().result()
        acq_np = np.asarray(acq_store[:, time_slice].read().result()).T
    else:
        traces_np = traces_store.read().result()
        acq_np = np.asarray(acq_store.read().result()).T

    T, N = traces_np.shape
    assert acq_np.shape == (T, N), (
        f"traces shape {traces_np.shape} != acq shape {acq_np.shape}"
    )

    # deterministic output size
    num_bins = int(np.ceil(T * frame_period_ms / bin_size_ms))

    # time within loaded window: t * frame_period_ms + offset
    frame_times = np.arange(T, dtype=np.float64) * frame_period_ms
    time_ms = frame_times[:, np.newaxis] + np.asarray(acq_np, dtype=np.float64)

    # quantize to bin indices, clamp to valid range
    bin_indices = np.floor(time_ms / bin_size_ms).astype(np.int64)
    np.clip(bin_indices, 0, num_bins - 1, out=bin_indices)

    # flatten for scatter
    traces_flat = torch.from_numpy(
        np.ascontiguousarray(traces_np, dtype=np.float32),
    ).reshape(-1)
    bins_flat = torch.from_numpy(
        np.ascontiguousarray(bin_indices.reshape(-1)),
    ).long()
    neurons_flat = (
        torch.arange(N, dtype=torch.long, device="cpu")
        .unsqueeze(0)
        .expand(T, N)
        .reshape(-1)
    )

    # scatter into (num_bins, N), unobserved entries are 0
    linear_idx = bins_flat * N + neurons_flat
    staggered = torch.zeros(num_bins * N, dtype=torch.float32, device="cpu")
    observed = torch.zeros(num_bins * N, dtype=torch.bool, device="cpu")
    staggered[linear_idx] = traces_flat
    observed[linear_idx] = True
    staggered = staggered.reshape(num_bins, N)
    observed = observed.reshape(num_bins, N)

    return staggered, observed


def interpolate_staggered_activity(
    staggered: torch.Tensor,
    observed: torch.Tensor,
) -> torch.Tensor:
    """linearly interpolate gaps in a staggered activity matrix.

    for each (t, n), finds the nearest observed entry before and after t
    in column n and linearly interpolates between them. at boundaries
    (no observation before or after), the nearest available observation
    is used (constant extrapolation).

    args:
        staggered: (T, N) float tensor, 0 at unobserved entries.
        observed: (T, N) bool tensor, True where staggered has a real value.

    returns:
        (T, N) float tensor with all gaps filled by interpolation.
    """
    T, N = staggered.shape
    device = staggered.device

    t_grid = torch.arange(T, device=device, dtype=torch.long).unsqueeze(1).expand(T, N)

    # last observed index <= t: set unobserved to -1, cummax forward
    lo_raw = torch.where(observed, t_grid, torch.tensor(-1, device=device, dtype=torch.long))
    t_lo = torch.cummax(lo_raw, dim=0).values  # (T, N)

    # next observed index >= t: set unobserved to T, flip, cummin, flip
    hi_raw = torch.where(observed, t_grid, torch.tensor(T, device=device, dtype=torch.long))
    t_hi = torch.cummin(hi_raw.flip(0), dim=0).values.flip(0)  # (T, N)

    # boundary: no prior obs -> use next; no next obs -> use prior
    has_lo = t_lo >= 0
    has_hi = t_hi < T
    t_lo = torch.where(has_lo, t_lo, t_hi.clamp(0, T - 1))
    t_hi = torch.where(has_hi, t_hi, t_lo.clamp(0, T - 1))

    # gather values
    neuron_idx = torch.arange(N, device=device, dtype=torch.long).unsqueeze(0).expand(T, N)
    val_lo = staggered[t_lo, neuron_idx]
    val_hi = staggered[t_hi, neuron_idx]

    # interpolation weight
    span = (t_hi - t_lo).float()
    t_float = t_grid.float()
    w = torch.where(span > 0, (t_float - t_lo.float()) / span, torch.zeros_like(span))

    return (1.0 - w) * val_lo + w * val_hi


interpolate_staggered_activity_compiled = torch.compile(
    interpolate_staggered_activity, mode="reduce-overhead", fullgraph=True,
)


# ---------------------------------------------------------------------------
# sparse path: zarr -> (N, K) sparse -> searchsorted interpolation
# ---------------------------------------------------------------------------

def load_sparse_activity(
    traces_path: str,
    acq_path: str,
    bin_size_ms: float,
    frame_period_ms: float,
    time_slice: slice | None = None,
) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor, int]:
    """load traces and acq from zarr directly into sparse representation.

    skips the intermediate dense (num_bins, N) matrix entirely. each
    raw observation (frame, neuron) maps to a bin index; we pack these
    per-neuron into (N, K_max) padded arrays sorted by bin time.

    since each frame contributes exactly one observation per neuron,
    K_max == T (number of loaded frames) and every neuron has the same
    count. padding is only needed if frames are subsetted unevenly,
    which doesn't happen in practice.

    args:
        traces_path: path to zarr array, shape (T, N).
        acq_path: path to zarr array, stored as (N, T).
        bin_size_ms: bin width in milliseconds.
        frame_period_ms: nominal interval between frames in ms.
        time_slice: optional slice along T axis.

    returns:
        obs_times: (N, K_max) long cpu tensor, sorted bin indices.
        obs_vals: (N, K_max) float32 cpu tensor, trace values.
        counts: (N,) long cpu tensor, observations per neuron.
        num_bins: total number of output time bins.
    """
    traces_np, acq_np, T = _load_zarr_arrays(traces_path, acq_path, time_slice)
    N = traces_np.shape[1]
    bin_indices, num_bins = _compute_bin_indices(acq_np, T, bin_size_ms, frame_period_ms)

    # bin_indices is (T, N) â€” each frame gives one obs per neuron.
    # transpose to (N, T) for per-neuron layout, already sorted by
    # frame order which is monotonically increasing in time.
    obs_times = torch.from_numpy(
        np.ascontiguousarray(bin_indices.T, dtype=np.int64),
    )  # (N, T)
    obs_vals = torch.from_numpy(
        np.ascontiguousarray(traces_np.T, dtype=np.float32),
    )  # (N, T)

    # every neuron has exactly T observations
    counts = torch.full((N,), T, dtype=torch.long, device="cpu")

    return obs_times, obs_vals, counts, num_bins


def load_and_interpolate(
    traces_path: str,
    acq_path: str,
    bin_size_ms: float,
    frame_period_ms: float,
    time_slice: slice | None = None,
    device: torch.device | str = "cpu",
) -> torch.Tensor:
    """load zarr data and produce interpolated dense activity on device.

    goes zarr -> sparse (N, K) on cpu -> transfer to device ->
    searchsorted interpolation -> (num_bins, N) dense result.
    never materializes the full dense staggered matrix on cpu or gpu.

    args:
        traces_path: path to zarr array, shape (T, N).
        acq_path: path to zarr array, stored as (N, T).
        bin_size_ms: bin width in milliseconds.
        frame_period_ms: nominal interval between frames in ms.
        time_slice: optional slice along T axis.
        device: target device for interpolation and output.

    returns:
        (num_bins, N) float32 tensor on device, fully interpolated.
    """
    obs_times, obs_vals, counts, num_bins = load_sparse_activity(
        traces_path, acq_path, bin_size_ms, frame_period_ms, time_slice,
    )
    obs_times = obs_times.to(device)
    obs_vals = obs_vals.to(device)
    counts = counts.to(device)
    return interpolate_sparse(obs_times, obs_vals, counts, num_bins)


def interpolate_sparse(
    obs_times: torch.Tensor,
    obs_vals: torch.Tensor,
    counts: torch.Tensor,
    T: int,
) -> torch.Tensor:
    """interpolate from padded sparse representation using searchsorted.

    for each target time t in [0, T) and each neuron n, finds the
    bracketing observations via binary search and linearly interpolates.
    at boundaries (before first / after last observation), the nearest
    observation is used (constant extrapolation).

    args:
        obs_times: (N, K_max) long tensor, sorted observation times.
            padded entries must be T+1.
        obs_vals: (N, K_max) float tensor, values at observation times.
        counts: (N,) long tensor, number of real observations per neuron.
        T: number of output time bins.

    returns:
        (T, N) float tensor with all time bins filled by interpolation.
    """
    device = obs_times.device
    N, K_max = obs_times.shape

    # target times: (N, T) for batched searchsorted
    target = torch.arange(T, device=device, dtype=torch.long)
    target_expanded = target.unsqueeze(0).expand(N, T).contiguous()  # (N, T)

    # searchsorted(right=False): index of first obs_time >= target.
    # padding at T+1 is beyond all targets, so it's never selected
    # unless the target is past the last real observation.
    idx_hi = torch.searchsorted(obs_times, target_expanded)  # (N, T)
    idx_lo = idx_hi - 1

    # clamp to valid observation range [0, count-1]
    max_idx = (counts.unsqueeze(1) - 1).clamp(min=0)  # (N, 1)
    idx_lo = torch.clamp(idx_lo, min=0)
    idx_lo = torch.min(idx_lo, max_idx)
    idx_hi = torch.clamp(idx_hi, min=0)
    idx_hi = torch.min(idx_hi, max_idx)

    # gather times and values at lo/hi
    t_lo = obs_times.gather(1, idx_lo)  # (N, T)
    t_hi = obs_times.gather(1, idx_hi)  # (N, T)
    v_lo = obs_vals.gather(1, idx_lo)   # (N, T)
    v_hi = obs_vals.gather(1, idx_hi)   # (N, T)

    # interpolation weight
    span = (t_hi - t_lo).float()
    offset = (target_expanded - t_lo).float()
    w = torch.where(span > 0, offset / span, torch.zeros_like(span))

    result = (1.0 - w) * v_lo + w * v_hi  # (N, T)
    return result.T  # (T, N)


interpolate_sparse_compiled = torch.compile(
    interpolate_sparse, mode="reduce-overhead", fullgraph=True,
)
