# Working Memory: signal_chaotic_1_Claude

## Knowledge Base (accumulated across all blocks)

### Regime Comparison Table

| Block | Regime                          | E/I | n_frames | n_neurons | n_types | eff_rank          | Best R² | Optimal lr_W     | Optimal L1 | Key finding                                                                              |
| ----- | ------------------------------- | --- | -------- | --------- | ------- | ----------------- | ------- | ---------------- | ---------- | ---------------------------------------------------------------------------------------- |
| 1     | chaotic, Dale_law=False         | -   | 10000    | 100       | 1       | 31-35             | 1.000   | 4E-3 to 4E-2     | ≤5E-4      | extremely robust; low_rank_factorization=True catastrophic                               |
| 2     | chaotic, Dale_law=True          | 0.5 | 10000    | 100       | 1       | 10                | 0.913   | 5E-2 to 1.2E-1   | ≤1E-5      | R² ceiling ~0.91 due to low eff_rank; needs 10-30x higher lr_W                           |
| 3     | low_rank (r=20), Dale_law=False | -   | 10000    | 100       | 1       | 6 (stochastic)    | 0.886\* | 8E-2 to 1E-1     | ≤1E-5      | \*not reproducible; eff_rank=6 in 15/16 runs creates R²<0.4 ceiling                      |
| 4     | low_rank (r=50), Dale_law=False | -   | 10000    | 100       | 1       | 7                 | 0.188   | 1.5E-1           | 1E-6       | factorization=True helps (10x), but eff_rank=7 hard ceiling                              |
| 5     | chaotic, Dale_law=False         | -   | 5000     | 100       | 1       | 20                | 0.924   | 2E-2 to 3E-2     | 1E-5       | n_frames reduction lowers eff_rank; needs 5-7x higher lr_W                               |
| 6     | chaotic, Dale_law=False         | -   | 2500     | 100       | 1       | 6\*               | 0.568   | N/A              | 1E-5       | \*94% eff_rank=6; below minimum data threshold; 0/16 converged                           |
| 7     | chaotic, Dale_law=False         | -   | 7500     | 100       | 1       | 25-29             | 0.989   | 3E-2 to 1.3E-1   | ≤5E-5      | intermediate data: R²=0.989 achievable; lr_W 40x range                                   |
| 8     | chaotic, Dale_law=True          | 0.5 | 10000    | 100       | 1       | 10 (94%), 27 (6%) | 0.995   | 8E-2 to 1.5E-1   | 1E-6       | eff_rank highly stochastic; eff_rank=27 → R²=0.995; eff_rank=10 → R²≤0.945               |
| 9     | low_rank (r=20), Dale_law=True  | 0.5 | 10000    | 100       | 1       | 16                | 0.540   | TBD              | 1E-6       | single iteration; eff_rank=16 (better than low_rank+Dale_law=False)                      |
| 10    | low_rank (r=20), Dale_law=True  | 0.5 | 10000    | 100       | 1       | 16                | 0.924   | 1.5E-2           | 1E-6       | low_rank factorization key: need low_rank≥60 (~3x connectivity_rank)                     |
| 11    | chaotic, Dale_law=False         | -   | 10000    | 1000      | 1       | 52-54             | 0.184   | 8E-3             | 1E-5       | n=1000 fundamentally harder; lr 50x higher needed (5E-3); R² ceiling ~0.18               |
| 12    | chaotic, Dale_law=False         | -   | 10000    | 1000      | 1       | 51-53             | 0.297   | 1.6E-2 to 2.4E-2 | 1E-8       | 2x training (120 loops) didn't break ceiling; parameter sweep complete                   |
| 13    | chaotic, Dale_law=True          | 0.5 | 10000    | 1000      | 1       | 35-38             | 0.256   | 1.5E-1           | 1E-7       | Dale_law lowers eff_rank (35-38 vs 52); R² slightly worse than no Dale_law               |
| 14    | low_rank (r=20), Dale_law=False | -   | 10000    | 1000      | 1       | 7-14              | 0.244\* | 2E-2             | 1E-7       | \*not reproducible; high stochasticity; factorization=True fails                         |
| 15    | chaotic, Dale_law=False         | -   | 50000    | 100       | 1       | 49-54             | 1.000   | 2.5E-4 to 2.0    | 1E-5       | 8000x lr_W range; best test_R2=0.996 at lr_W=5E-4; L1=1E-5 optimal for generalization    |
| 16    | chaotic, Dale_law=False         | -   | 50000    | 1000      | 1       | 94                | 0.969   | 5E-3 to 3.2E-1   | 1E-8       | BREAKTHROUGH: n_frames=50000 breaks n=1000 ceiling (0.30→0.97); eff_rank 52→94           |
| 17    | chaotic, Dale_law=True          | 0.5 | 50000    | 1000      | 1       | 80-83             | 0.995   | 5E-3 to 1E-2     | 1E-7       | n_frames=50000 breaks Dale_law+n=1000 ceiling (0.26→0.995); eff_rank 35→80               |
| 18    | low_rank (r=20), Dale_law=True  | 0.5 | 50000    | 1000      | 1       | TBD               | 0.974   | 1E-2             | 1E-7       | n_frames=50000 breaks low_rank ceiling (0.24→0.97); single iteration only                |
| 19    | low_rank (r=20), Dale_law=False | -   | 50000    | 1000      | 1       | TBD               | 0.858   | 1.8E-2           | 1E-8       | n_frames=50000: 0.24→0.86; extreme stochasticity; Dale_law=False harder than True        |
| 20    | chaotic, Dale_law=False         | -   | 10000    | 100       | 4       | 31-35             | 0.925   | 8E-3             | 1E-5       | n_types=4: R2 same as n_types=1; cluster_accuracy=0.25 (random); embeddings NOT learning |
| 21    | chaotic, Dale_law=True          | 0.5 | 10000    | 100       | 4       | 10-27             | 0.957   | 8E-3 to 1.5E-1   | 1E-5       | Dale_law does NOT help cluster learning; cluster_accuracy=0.25 for 16/16 runs            |
| 22    | chaotic, Dale_law=False         | -   | 50000    | 100       | 4       | TBD               | 0.996   | 8E-3             | 1E-6       | n_frames=50000 does NOT fix embedding failure; cluster_accuracy=0.25-0.50 (random)       |

### Established Principles

1. chaotic full-rank connectivity: lr_W has 10x robust range (4E-3 to 4E-2) at n_frames=10000
2. L1 regularization boundary: regime-dependent (Dale_law=False: ≤5E-4, Dale_law=True: ≤1E-5, low_rank: ≤1E-6)
3. low_rank_factorization=True: fails on chaotic connectivity; HELPS on low_rank connectivity (when factorization rank ≥ connectivity rank)
4. batch_size (8, 16, 32) does not affect convergence in any tested regime
5. Dale_law=True: eff_rank stochastic (Block 2: eff_rank≈10, Block 8: eff_rank=10-27) - NOT deterministic
6. effective_rank determines R² ceiling: eff_rank=6 → R²≈0.15-0.57; eff_rank=10 → R²≈0.91-0.95; eff_rank=16 → R²≈0.92; eff_rank≥25 → R²≈0.99; eff_rank=32 → R²=1.0
7. Dale_law=True requires 10-30x higher lr_W than Dale_law=False
8. lr/lr_W ratio matters: optimal ~300:1 to 400:1 for low_rank+Dale_law (lr_W=1.5E-2, lr=5E-5)
9. low_rank connectivity produces lower eff_rank than chaotic; high stochasticity in eff_rank
10. lr_W optimal range is regime-dependent: chaotic ~4E-3, Dale_law=True ~8E-2 to 1.5E-1, low_rank+Dale_law ~1.5E-2
11. connectivity_rank does NOT meaningfully affect eff_rank (rank=50 gave eff_rank=7, similar to rank=20 with eff_rank=6)
12. n_frames affects eff_rank: n_frames=2500 → eff_rank≈6; n_frames=5000 → eff_rank≈20; n_frames=7500 → eff_rank≈27; n_frames=10000 → eff_rank≈32; n_frames=50000 → eff_rank≈54
13. lower eff_rank requires higher lr_W: eff_rank=20 (n_frames=5000) needs 5-7x higher lr_W (2E-2 to 3E-2 vs 4E-3)
14. **minimum n_frames for chaotic regime ≈ 5000** (n_frames=2500 fails 94% with eff_rank=6)
15. n_frames=7500 provides good balance: eff_rank≈27, R²=0.989 achievable, 40x lr_W range
16. **eff_rank=10 ceiling can reach R²=0.945** with optimized params (lr_W=1.5E-1, lr=1E-4, L1=1E-6)
17. **low_rank factorization dimension critical**: for low_rank connectivity, need low_rank ≥ 3x connectivity_rank for convergence (e.g., connectivity_rank=20 needs low_rank≥60)
18. **n_neurons=1000 dramatically harder**: eff_rank=52 (vs 32 for n=100); R² ceiling ~0.30 with optimized params
19. **n=1000 requires higher MLP lr**: optimal lr=5E-3 (50x higher than n=100's lr=1E-4); lr_W optimal ~1.6E-2 to 2.4E-2
20. **lr/lr_W ratio depends on n_neurons**: n=100 → ratio 1:40 (lr=1E-4, lr_W=4E-3); n=1000 → ratio 1:3.2 (lr=5E-3, lr_W=1.6E-2)
21. **n=1000 L1 boundary much lower**: optimal L1≤1E-7 (vs 1E-5 for n=100); L1=1E-8 floor reached
22. **n=1000 + Dale_law=True**: eff_rank=35-38 (lower than 52 without Dale_law); lr_W optimal 1E-1 to 1.5E-1; R² ceiling ~0.26 (slightly worse than no Dale_law's 0.30)
23. **n=1000 + low_rank connectivity**: eff_rank=7-14 (dramatically lower than chaotic's 52); peak at lr_W=2E-2, lr=1E-2; EXTREMELY stochastic (same config: R²=0.01-0.24); factorization=True still fails
24. **high n_frames (50000) gives extraordinary lr_W robustness**: 8000x range (2.5E-4 to 2.0) for chaotic n=100; confirms more data → more robust training
25. **L1 affects generalization (test_R2)**: L1=1E-5 optimal for test_R2; L1=1E-7 degrades test_R2 by ~0.1-0.3 even though connectivity_R2 converges
26. **n=1000 + high n_frames (50000) BREAKTHROUGH**: eff_rank 52→94 (+80%); R² ceiling 0.30→0.97; confirms data quantity critical for n=1000
27. **n=1000 + n_frames=50000 optimal params**: lr_W=2E-2 (5E-3 to 3.2E-1 64x range); lr=5E-3 (2E-3 to 2E-2 10x range); L1=1E-8
28. **n=1000 + Dale_law=True + n_frames=50000**: eff_rank 35→80-83 (+2.2x); R² ceiling 0.26→0.995; optimal lr_W=5E-3 to 1E-2, lr=5E-3, L1=1E-7
29. **n=1000 + low_rank + Dale_law + n_frames=50000**: R²=0.974 (single run); breaks 0.24 ceiling; params transfer from chaotic regime
30. **low_rank + Dale_law=False harder than +Dale_law=True** at n=1000: R²=0.86 vs 0.97; confirmed across Blocks 18-19; likely due to sign constraints providing better conditioning
31. **n_neuron_types>1 does NOT help cluster learning**: n_types=4 tested with 200x lr_emb range (1E-4 to 2E-2); cluster_accuracy=0.25 (random chance) for all 16 runs; embeddings NOT learning neuron types
32. **n_neuron_types does NOT affect connectivity training**: optimal params same as n_types=1 (lr_W=8E-3, lr=5E-4, L1=1E-5); R2=0.925 achievable
33. **EMBEDDING FAILURE IS ARCHITECTURAL**: tested across Blocks 20-22 (48 runs total): lr_emb (5E-5 to 1E-1, 2000x), lr (1E-4 to 1E-2, 100x), lr_W (5E-4 to 8E-3), L1, batch_size, fix_cluster_embedding, data_augmentation_loop, n_frames (10k, 50k), n_types (2, 4) - ALL give random cluster_accuracy

### Open Questions

- why does Dale_law=True sometimes give eff_rank≈10 (94%) vs eff_rank=27 (6%)? stochasticity in initialization?
- **embedding failure CONFIRMED as architectural** - further investigation requires code changes, not hyperparameter tuning
- can n=1000 reach R²=1.000 with n_frames=100k?
- does the low_rank ≥ 3x connectivity_rank rule generalize to other regimes?

---

## Previous Block Summary

**Block 22** (chaotic, Dale_law=False, n_frames=50000, n_neurons=100, n_neuron_types=4): 16/16 converged, best R²=0.996 (at n_types=2).
cluster_accuracy=0.25 (random) for ALL 14 n_types=4 runs, 0.50 for 2 n_types=2 runs; **embedding failure confirmed as ARCHITECTURAL** (not data-limited); tested 2000x lr_emb range.

---

## Current Block (Block 23)

### Block Info

Simulation: connectivity_type=chaotic, Dale_law=False, n_frames=100000, n_neurons=1000, n_neuron_types=1
Iterations: 321 to 336

### Hypothesis

Testing if n_frames=100000 can push n=1000 to R²=1.000:

1. Block 16 showed n_frames=50000 gave R²=0.969 for n=1000 (vs 0.30 at n_frames=10000)
2. Block 15 showed n=100 reaches R²=1.000 with n_frames=50000
3. hypothesis: doubling n_frames (50k→100k) may provide enough data for n=1000 to reach R²=1.0
4. start with Block 16 optimal params: lr_W=2E-2, lr=5E-3, L1=1E-8
5. prediction: if R²>0.99, more data helps; if R²≈0.97, n=1000 may have architectural ceiling

### Iterations This Block

(starting Block 23)

### Emerging Observations

(pending first iteration)
