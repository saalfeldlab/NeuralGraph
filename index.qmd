---
title: "Experiment-LLM-Memory"
subtitle: "Closed-loop scientific exploration in neural connectivity inference"
author: "CÃ©dric Allier, Stephan Saalfeld"
date: "2026-01-28"
---

## Introduction

We previously showed that graph neural networks can recover circuit structure and signaling functions of neural assemblies from activity data alone. However, this inverse problem is known to be ill-posed under certain conditions. For instance, when neural activity is low-rank, many different circuits can generate the same neuron traces. It remains an open question whether graph neural networks can recover connectivity in general, or only for specific classes of neural assemblies.

To address this question, we extend our graph neural network framework with a large language model. In this new setup, the role of the graph neural network framework is to perform experiments and deliver quantified results. The role of the large language model is to interpret, compare and finally compress the experiment results into structured memory. On the basis thereof, the large language model is next prompted to mutate selectively the neural dynamics configuration and/or the graph neural network training scheme.

We show that these sequential interactions between experimentation, large language model and long-term memory, lead progressively to a scientific tool. Testable hypotheses are drawn, repeatable experiments are conducted to validate or falsify them, and ultimately causal understanding emerges. Importantly, the **closed-loop scientific reasoning results from the interactions between the three components** rather than residing solely within the large language model.

---

## The Exploration Loop

```{mermaid}
%%| fig-width: 6
flowchart LR
    A[Experiment] --> B[LLM]
    B --> A

    B --> C[(Memory)]
    C --> B

    style A fill:#e1f5fe
    style B fill:#fff3e0
    style C fill:#f3e5f5
```

The framework implements a **closed-loop exploration engine** composed of three interacting components:

1. **Experiment**
   A physics-based simulator generates neural activity following the Stern et al. (2023) model. A message-passing GNN learns to predict activity derivatives while jointly recovering the connectivity matrix W.

2. **LLM**
   The LLM interprets results in context of accumulated memory, performs scientific operations (identify regimes, detect convergence, generate hypotheses), and selects the next intervention via UCB tree search.

3. **Memory**
   Observations, failed attempts, and validated principles are written into explicit long-term memory. This memory persists across experimental blocks, enabling cumulative understanding rather than episodic trial-and-error.

---

## [Results](results.qmd)

12 principles discovered across 14 simulation regimes. Effective rank determines training difficulty (97% confidence). Sparse connectivity (ff<0.3) is fundamentally unrecoverable.

[![](assets/landscape_quadrant.png){.lightbox}](results.qmd)

---

## [Epistemics](epistemic-analysis.qmd)

231 reasoning events across 107 iterations. 69% deduction accuracy, 80% analogy transfer success, 100% of falsifications led to refinement.

[![](assets/Sankey.png){.lightbox}](epistemic-analysis.qmd)

---

## References

1. Stern, M., et al. (2023). Graph neural networks uncover structure and function underlying the activity of neural assemblies.

2. Romera-Paredes, B., et al. (2024). Mathematical discoveries from program search with large language models. *Nature*.

3. Novikov, A., et al. (2025). AlphaEvolve: A coding agent for scientific and algorithmic exploration.
